{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERWFXY5O9_uT"
      },
      "source": [
        "\n",
        "Entailment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68r5y5hlsnju",
        "outputId": "cc70efb4-81b4-410f-d93a-2c2d7d67d1d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2a222c2af08038a2e4c4a940bf4722c0766c48fac6535b9003ab351f0b174d01\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwd0sBy-snnD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhj8FzPfsnqK",
        "outputId": "f9a5c416-1db8-4ed8-95ac-0e70f4cb947d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    max_length = 256\n",
        "\n",
        "    premise = \"Replacing entire Cisco 3750 Stack with Cisco 9300 Stack.\"\n",
        "    hypothesis = \"3750 dhcp remembered ,sometimes give automatic leases\"\n",
        "\n",
        "    hg_model_hub_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
        "    # hg_model_hub_name = \"ynie/albert-xxlarge-v2-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
        "    # hg_model_hub_name = \"ynie/bart-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
        "    # hg_model_hub_name = \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
        "    # hg_model_hub_name = \"ynie/xlnet-large-cased-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
        "\n",
        "    tokenized_input_seq_pair = tokenizer.encode_plus(premise, hypothesis,\n",
        "                                                     max_length=max_length,\n",
        "                                                     return_token_type_ids=True, truncation=True)\n",
        "\n",
        "    input_ids = torch.Tensor(tokenized_input_seq_pair['input_ids']).long().unsqueeze(0)\n",
        "    # remember bart doesn't have 'token_type_ids', remove the line below if you are using bart.\n",
        "    token_type_ids = torch.Tensor(tokenized_input_seq_pair['token_type_ids']).long().unsqueeze(0)\n",
        "    attention_mask = torch.Tensor(tokenized_input_seq_pair['attention_mask']).long().unsqueeze(0)\n",
        "\n",
        "    outputs = model(input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=token_type_ids,\n",
        "                    labels=None)\n",
        "    # Note:\n",
        "    # \"id2label\": {\n",
        "    #     \"0\": \"entailment\",\n",
        "    #     \"1\": \"neutral\",\n",
        "    #     \"2\": \"contradiction\"\n",
        "    # },\n",
        "\n",
        "    predicted_probability = torch.softmax(outputs[0], dim=1)[0].tolist()  # batch_size only one\n",
        "\n",
        "    print(\"Premise:\", premise)\n",
        "    print(\"Hypothesis:\", hypothesis)\n",
        "    print(\"Entailment:\", predicted_probability[0])\n",
        "    print(\"Neutral:\", predicted_probability[1])\n",
        "    print(\"Contradiction:\", predicted_probability[2])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Premise: Replacing entire Cisco 3750 Stack with Cisco 9300 Stack.\n",
            "Hypothesis: 3750 dhcp remembered ,sometimes give automatic leases\n",
            "Entailment: 0.0027900233399122953\n",
            "Neutral: 0.9362196922302246\n",
            "Contradiction: 0.060990240424871445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjvu9ZmssntT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqoS2V6WsnwM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0J4lzpfsnzE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mif8UyO5sn1x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfbB6ezJsn4h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9iMDWqisn74"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}