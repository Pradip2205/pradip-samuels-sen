{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cddd104c2d94227a2d44c0f33433707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c56d0df326fb4e5e9711d5b82fa97332",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8df5bd8ec08241a2934377cbfbe6e202",
              "IPY_MODEL_95f1aad4c86a4162b9d0920e8a7dd6f3"
            ]
          }
        },
        "c56d0df326fb4e5e9711d5b82fa97332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8df5bd8ec08241a2934377cbfbe6e202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c16cbbbcd63c415bbde5f4fa527e9b5b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1081,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1081,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a7b3b2dd69041fe99ab55752efa2066"
          }
        },
        "95f1aad4c86a4162b9d0920e8a7dd6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_107e61cde3f04055b896bfde3073b816",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08k/1.08k [00:06&lt;00:00, 155B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_667a6ecd2f1640cb8ce11441d1ade497"
          }
        },
        "c16cbbbcd63c415bbde5f4fa527e9b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a7b3b2dd69041fe99ab55752efa2066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "107e61cde3f04055b896bfde3073b816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "667a6ecd2f1640cb8ce11441d1ade497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87461e08888b4660a54e47f042e152c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85a08b90c31d40c1962b3722fd083e2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ca964f9d6ee40f6a9b34c5869d6970d",
              "IPY_MODEL_c9d8b238b9a54f48b9866eb5513c130d"
            ]
          }
        },
        "85a08b90c31d40c1962b3722fd083e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ca964f9d6ee40f6a9b34c5869d6970d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06a81ae807304a6f9c0b2f41c3528bf2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 438206084,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 438206084,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5aecdc00472411eb5851eca61c5480b"
          }
        },
        "c9d8b238b9a54f48b9866eb5513c130d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49ce9337e1ef44349257849668699030",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 438M/438M [00:06&lt;00:00, 70.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe126f0a97504c0680bc356bfcb234e9"
          }
        },
        "06a81ae807304a6f9c0b2f41c3528bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5aecdc00472411eb5851eca61c5480b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49ce9337e1ef44349257849668699030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe126f0a97504c0680bc356bfcb234e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2893a1681346476a810e95dcccc1cf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45afb21d59a648a99c12f5534c0a02e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f32901a56e0847eb87d26ee260b19255",
              "IPY_MODEL_ddd77cb7e1b94698b7957811360bf15c"
            ]
          }
        },
        "45afb21d59a648a99c12f5534c0a02e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f32901a56e0847eb87d26ee260b19255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78320b3fcc774f0596d061229fd357d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 829,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 829,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0889afbce714b8d82081ad8090ee751"
          }
        },
        "ddd77cb7e1b94698b7957811360bf15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6e786d037374a4286bd4817ca953527",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 829/829 [00:00&lt;00:00, 19.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f40645d54c3146249c4feee859ec5547"
          }
        },
        "78320b3fcc774f0596d061229fd357d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0889afbce714b8d82081ad8090ee751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6e786d037374a4286bd4817ca953527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f40645d54c3146249c4feee859ec5547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90782ae19524410e9dd05e3a69bcc317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55a282c0f05d4933a37cd30a11e66623",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efb139b0439244989931a11950ce40c4",
              "IPY_MODEL_f4462d9224384dc1ada6c56d5ef74457"
            ]
          }
        },
        "55a282c0f05d4933a37cd30a11e66623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efb139b0439244989931a11950ce40c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13912e46a73048d1acc6d14ed0bfb197",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84de798a767248db9fb4f54199071541"
          }
        },
        "f4462d9224384dc1ada6c56d5ef74457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f35516fd86d4fc9a2a7119f68234787",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:01&lt;00:00, 155kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_636484925ff74c1787d8253bba87e9fa"
          }
        },
        "13912e46a73048d1acc6d14ed0bfb197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84de798a767248db9fb4f54199071541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f35516fd86d4fc9a2a7119f68234787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "636484925ff74c1787d8253bba87e9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d93bc91733b402c961873a8a81933fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38f73f92f4dc4201bc61c7fa483ae33a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_436ea7b4cd3e4b34a8e2be38707d46d0",
              "IPY_MODEL_fb2ef37a6d7146fda1657b258c7c3ae6"
            ]
          }
        },
        "38f73f92f4dc4201bc61c7fa483ae33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "436ea7b4cd3e4b34a8e2be38707d46d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4aa9bc1a16aa441ca68a9ed9c2d6f572",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a960736bbd4347fb9258fc7653731357"
          }
        },
        "fb2ef37a6d7146fda1657b258c7c3ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_007b71b5ad4f4f7790f90dc2992a04ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 3.33B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46eb97faa08948498cdc54544096ddba"
          }
        },
        "4aa9bc1a16aa441ca68a9ed9c2d6f572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a960736bbd4347fb9258fc7653731357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "007b71b5ad4f4f7790f90dc2992a04ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46eb97faa08948498cdc54544096ddba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47a17ed6402e4638a7960608753ed249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_286b5f5c1e104a189a1e222186805169",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd6e93142657495cb8c8fe56641a300b",
              "IPY_MODEL_78bb4789ba7348d19f00eef442427984"
            ]
          }
        },
        "286b5f5c1e104a189a1e222186805169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd6e93142657495cb8c8fe56641a300b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61d422d218794e568c2c5cf7f7f3d967",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00a4351a34ec402b98e070df07afd112"
          }
        },
        "78bb4789ba7348d19f00eef442427984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3627427f043476289b4f6d072a19ba5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 123B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef7802cca85b4199b7c8dc0c2f46eee0"
          }
        },
        "61d422d218794e568c2c5cf7f7f3d967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00a4351a34ec402b98e070df07afd112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3627427f043476289b4f6d072a19ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef7802cca85b4199b7c8dc0c2f46eee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d327dd3d6a574069b749668295206237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe69513485e24ede9d72b5936300167d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76d3453f474e42649a42c05bdaa5af14",
              "IPY_MODEL_b63dec87328e489ea367f08cbf11ded8"
            ]
          }
        },
        "fe69513485e24ede9d72b5936300167d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76d3453f474e42649a42c05bdaa5af14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28d96e05da9448ac995e0ab6b1a914fa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73f250d5afe1479c808c6f0651afdd7c"
          }
        },
        "b63dec87328e489ea367f08cbf11ded8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c27a6dd3109d4a5ca85d5f690d864690",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59.0/59.0 [00:00&lt;00:00, 181B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7818d8436f744fa199fe2ff514be65a9"
          }
        },
        "28d96e05da9448ac995e0ab6b1a914fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73f250d5afe1479c808c6f0651afdd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c27a6dd3109d4a5ca85d5f690d864690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7818d8436f744fa199fe2ff514be65a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1cdacce24e04fa8a66c02d9bbde0827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e807b91bdf854a6a8efd2ae3e62023d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb172b0fc5c8486991154c27170afa37",
              "IPY_MODEL_a726251ccc794684ad24b512d69068a5"
            ]
          }
        },
        "e807b91bdf854a6a8efd2ae3e62023d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb172b0fc5c8486991154c27170afa37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0729f35707614a05bc1be7bd844446b3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433316646,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433316646,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc830575dbef413192420fcecee66948"
          }
        },
        "a726251ccc794684ad24b512d69068a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09d0c3d81a0c40338f24cd96c6bd004a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433M/433M [00:12&lt;00:00, 34.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0508e589026740ed8b5e2039ea7fa4af"
          }
        },
        "0729f35707614a05bc1be7bd844446b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc830575dbef413192420fcecee66948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09d0c3d81a0c40338f24cd96c6bd004a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0508e589026740ed8b5e2039ea7fa4af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M532Tb_uDcUp"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zphe3qgDcct",
        "outputId": "9b0c667b-9c36-45bf-e70b-50564b8bbde1"
      },
      "source": [
        "pip install aspect-based-sentiment-analysis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aspect-based-sentiment-analysis\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/93/06909b26a57bb759766d46d05fa9a598604d27f71cec4880e53f20921395/aspect_based_sentiment_analysis-2.0.1-py3-none-any.whl\n",
            "Collecting transformers>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from aspect-based-sentiment-analysis) (1.18.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from aspect-based-sentiment-analysis) (2.2.4)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.6/dist-packages (from aspect-based-sentiment-analysis) (2.3.0)\n",
            "Collecting testfixtures\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/2e/7420241d31f68a6e226cfa7da832b6a0e07bf3d2433d8f77d43cf4c31f4a/testfixtures-6.15.0-py2.py3-none-any.whl (90kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 8.7MB/s \n",
            "\u001b[?25hCollecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 27.3MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from aspect-based-sentiment-analysis) (3.6.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from aspect-based-sentiment-analysis) (0.22.2.post1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from aspect-based-sentiment-analysis) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 39.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.5->aspect-based-sentiment-analysis) (20.4)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->aspect-based-sentiment-analysis) (1.0.3)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->aspect-based-sentiment-analysis) (1.17.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->aspect-based-sentiment-analysis) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (2.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (50.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (3.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (1.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->aspect-based-sentiment-analysis) (1.1.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->aspect-based-sentiment-analysis) (3.3.0)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/3c/06c76ec8b54b9b1fad7f35e903fd25010fe3e0d41bd94cea5e6f12e0d651/cmaes-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna->aspect-based-sentiment-analysis) (0.17.0)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 39.8MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/61/5b64d73b01c1218f55c894b5ec0fb89b32c6960b7f7b3ad9f5ac0c373b9d/cliff-3.5.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 8.0MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/c8/c16d30bbed11a1722060014c246d124582d1f781b26f5859d8dacc3e08e1/colorlog-4.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna->aspect-based-sentiment-analysis) (1.3.20)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->aspect-based-sentiment-analysis) (1.9.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->aspect-based-sentiment-analysis) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->aspect-based-sentiment-analysis) (8.6.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->aspect-based-sentiment-analysis) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->aspect-based-sentiment-analysis) (20.3.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->aspect-based-sentiment-analysis) (1.0.18)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.5->aspect-based-sentiment-analysis) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.5->aspect-based-sentiment-analysis) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.5->aspect-based-sentiment-analysis) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.5->aspect-based-sentiment-analysis) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.5->aspect-based-sentiment-analysis) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.5->aspect-based-sentiment-analysis) (2.4.7)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->aspect-based-sentiment-analysis) (1.16.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->aspect-based-sentiment-analysis) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->aspect-based-sentiment-analysis) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->aspect-based-sentiment-analysis) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->aspect-based-sentiment-analysis) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->aspect-based-sentiment-analysis) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->aspect-based-sentiment-analysis) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->aspect-based-sentiment-analysis) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->aspect-based-sentiment-analysis) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna->aspect-based-sentiment-analysis) (2.8.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 10.1MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->aspect-based-sentiment-analysis) (3.13)\n",
            "Collecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/54/af6e2703f064485d717cb311d3f9440cd302a823ba6d80a020b59eae166d/cmd2-1.4.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 42.0MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 26.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->aspect-based-sentiment-analysis) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->aspect-based-sentiment-analysis) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->aspect-based-sentiment-analysis) (0.2.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->aspect-based-sentiment-analysis) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->aspect-based-sentiment-analysis) (1.52.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.2.0->google-cloud-storage->aspect-based-sentiment-analysis) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->aspect-based-sentiment-analysis) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1->aspect-based-sentiment-analysis) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna->aspect-based-sentiment-analysis) (1.1.1)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1->aspect-based-sentiment-analysis) (3.1.0)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-cp36-none-any.whl size=359761 sha256=a2815989859156a286f47af8a2cf9dcf082d24ed5180d42c1ed1cc83e6f75fe5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: sacremoses, PrettyTable, pyperclip\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1ab084aaf9705cfacdfd7ac4c1a3b24d7fd1a3e2b182152144fd889643515e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=227040f50bc71cb10cedac5e07ce1860dcfa3cfd7ad5f7d13138f593f76e1c61\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=f57ab20f627eeeab609b3582686df966e6b11084a6477da4fbdebc863bba028d\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built sacremoses PrettyTable pyperclip\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, testfixtures, cmaes, python-editor, Mako, alembic, pbr, stevedore, PrettyTable, colorama, pyperclip, cmd2, cliff, colorlog, optuna, aspect-based-sentiment-analysis\n",
            "  Found existing installation: prettytable 2.0.0\n",
            "    Uninstalling prettytable-2.0.0:\n",
            "      Successfully uninstalled prettytable-2.0.0\n",
            "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 aspect-based-sentiment-analysis-2.0.1 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorama-0.4.4 colorlog-4.6.2 optuna-2.3.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 sacremoses-0.0.43 stevedore-3.3.0 testfixtures-6.15.0 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdgRELtsLTTy"
      },
      "source": [
        " **Inferencing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ipLupMRxDcer",
        "outputId": "80f7169b-85d4-49d3-b7ec-de489d119168"
      },
      "source": [
        "import aspect_based_sentiment_analysis as absa\n",
        "\n",
        "nlp = absa.load()\n",
        "text = (\"We are great fans of Slack, but we wish the subscriptions \"\n",
        "        \"were more accessible to small startups.\")\n",
        "\n",
        "slack, price = nlp(text, aspects=['slack', 'price'])\n",
        "#assert price.sentiment == absa.Sentiment.negative\n",
        "#assert slack.sentiment == absa.Sentiment.positive"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cd71e9557864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maspect_based_sentiment_analysis\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mabsa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m text = (\"We are great fans of Slack, but we wish the subscriptions \"\n\u001b[1;32m      5\u001b[0m         \"were more accessible to small startups.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/aspect_based_sentiment_analysis/loads.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, text_splitter, reference_recognizer, pattern_recognizer, **model_kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertABSCConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertABSClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprofessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProfessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_recognizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern_recognizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_pytorch_checkpoint_in_tf2_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_missing_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error retrieving file {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/aspect_based_sentiment_analysis/models.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, token_ids, attention_mask, token_type_ids, training, **bert_kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2618\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2619\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer classifier is incompatible with the layer: : expected min_ndim=2, found ndim=0. Full shape received: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uSyvpdoe2hy",
        "outputId": "733c25e6-311d-4542-b890-92f8039a0a58"
      },
      "source": [
        "help(absa.load_examples)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function load_examples in module aspect_based_sentiment_analysis.loads:\n",
            "\n",
            "load_examples(dataset:str='semeval', domain:str='laptop', test:bool=False) -> List[aspect_based_sentiment_analysis.data_types.LabeledExample]\n",
            "    Download a dataset from the bucket if it is needed.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Pv40vLDcgf",
        "outputId": "4576dedc-90ee-47f9-88d7-caaef33b57dd"
      },
      "source": [
        "absa.summary(price)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment.negative for \"price\"\n",
            "Scores (neutral/negative/positive): [0.012 0.958 0.03 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPQGWAh9Dc6k",
        "outputId": "5b7675eb-ef23-434b-984d-09e600872a9c"
      },
      "source": [
        "absa.summary(slack)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment.positive for \"slack\"\n",
            "Scores (neutral/negative/positive): [0.001 0.001 0.997]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpA5GGLuDdKS"
      },
      "source": [
        "slack, accessible = nlp(text, aspects=['slack', 'accessible'])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OdSMZ1PDdaB",
        "outputId": "f1c6d26b-3f01-49ed-aaef-82a13bb804d8"
      },
      "source": [
        "absa.summary(accessible)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment.negative for \"accessible\"\n",
            "Scores (neutral/negative/positive): [0.005 0.984 0.011]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QedA44HrLMGA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtS-uzoGLn1c"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "TVcjUcfwLMT5",
        "outputId": "aa2e22e2-5bab-47a9-bbd8-3380804813df"
      },
      "source": [
        "import aspect_based_sentiment_analysis as absa\n",
        "\n",
        "recognizer = absa.aux_models.BasicPatternRecognizer()\n",
        "nlp = absa.load(pattern_recognizer=recognizer)\n",
        "completed_task = nlp(text=text, aspects=['slack', 'price'])\n",
        "slack, price = completed_task.examples\n",
        "\n",
        "absa.summary(slack)\n",
        "absa.display(slack.review)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at absa/classifier-rest-0.2 were not used when initializing BertABSClassifier: ['dropout_379']\n",
            "- This IS expected if you are initializing BertABSClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertABSClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of BertABSClassifier were not initialized from the model checkpoint at absa/classifier-rest-0.2 and are newly initialized: ['dropout_151']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentiment.positive for \"slack\"\n",
            "Scores (neutral/negative/positive): [0.001 0.001 0.997]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"background-color:rgba(180,180,180,1.1111111111111112);\">Importance 1.00</span> <span style=\"background-color:rgba(135,206,250,0.27499999999999997);\">we</span> <span style=\"background-color:rgba(135,206,250,0.43749999999999994);\">are</span> <span style=\"background-color:rgba(135,206,250,0.7499999999999999);\">great</span> <span style=\"background-color:rgba(135,206,250,1.25);\">fans</span> <span style=\"background-color:rgba(135,206,250,0.575);\">of</span> <span style=\"background-color:rgba(135,206,250,1.25);\">slack</span> <span style=\"background-color:rgba(135,206,250,0.1625);\">,</span> <span style=\"background-color:rgba(135,206,250,0.25);\">but</span> <span style=\"background-color:rgba(135,206,250,0.075);\">we</span> <span style=\"background-color:rgba(135,206,250,0.11249999999999999);\">wish</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">the</span> <span style=\"background-color:rgba(135,206,250,0.13749999999999998);\">subscriptions</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">were</span> <span style=\"background-color:rgba(135,206,250,0.0375);\">more</span> <span style=\"background-color:rgba(135,206,250,0.125);\">accessible</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">to</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">small</span> <span style=\"background-color:rgba(135,206,250,0.125);\">startups</span> <span style=\"background-color:rgba(135,206,250,0.125);\">.</span><br> <span style=\"background-color:rgba(180,180,180,1.0);\">Importance 0.90</span> <span style=\"background-color:rgba(135,206,250,0.2875);\">we</span> <span style=\"background-color:rgba(135,206,250,0.35000000000000003);\">are</span> <span style=\"background-color:rgba(135,206,250,1.125);\">great</span> <span style=\"background-color:rgba(135,206,250,1.125);\">fans</span> <span style=\"background-color:rgba(135,206,250,0.425);\">of</span> <span style=\"background-color:rgba(135,206,250,1.125);\">slack</span> <span style=\"background-color:rgba(135,206,250,0.13749999999999998);\">,</span> <span style=\"background-color:rgba(135,206,250,0.39999999999999997);\">but</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">we</span> <span style=\"background-color:rgba(135,206,250,0.1625);\">wish</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">the</span> <span style=\"background-color:rgba(135,206,250,0.13749999999999998);\">subscriptions</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">were</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">more</span> <span style=\"background-color:rgba(135,206,250,0.08750000000000001);\">accessible</span> <span style=\"background-color:rgba(135,206,250,0.0375);\">to</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">small</span> <span style=\"background-color:rgba(135,206,250,0.09999999999999999);\">startups</span> <span style=\"background-color:rgba(135,206,250,0.11249999999999999);\">.</span><br> <span style=\"background-color:rgba(180,180,180,0.6666666666666666);\">Importance 0.60</span> <span style=\"background-color:rgba(135,206,250,0.1625);\">we</span> <span style=\"background-color:rgba(135,206,250,0.125);\">are</span> <span style=\"background-color:rgba(135,206,250,0.5125);\">great</span> <span style=\"background-color:rgba(135,206,250,0.5249999999999999);\">fans</span> <span style=\"background-color:rgba(135,206,250,0.7499999999999999);\">of</span> <span style=\"background-color:rgba(135,206,250,0.7499999999999999);\">slack</span> <span style=\"background-color:rgba(135,206,250,0.39999999999999997);\">,</span> <span style=\"background-color:rgba(135,206,250,0.37499999999999994);\">but</span> <span style=\"background-color:rgba(135,206,250,0.075);\">we</span> <span style=\"background-color:rgba(135,206,250,0.08750000000000001);\">wish</span> <span style=\"background-color:rgba(135,206,250,0.09999999999999999);\">the</span> <span style=\"background-color:rgba(135,206,250,0.15);\">subscriptions</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">were</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">more</span> <span style=\"background-color:rgba(135,206,250,0.125);\">accessible</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">to</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">small</span> <span style=\"background-color:rgba(135,206,250,0.11249999999999999);\">startups</span> <span style=\"background-color:rgba(135,206,250,0.17500000000000002);\">.</span><br> <span style=\"background-color:rgba(180,180,180,0.4555555555555555);\">Importance 0.41</span> <span style=\"background-color:rgba(135,206,250,0.09999999999999999);\">we</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">are</span> <span style=\"background-color:rgba(135,206,250,0.18749999999999997);\">great</span> <span style=\"background-color:rgba(135,206,250,0.13749999999999998);\">fans</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">of</span> <span style=\"background-color:rgba(135,206,250,0.3);\">slack</span> <span style=\"background-color:rgba(135,206,250,0.125);\">,</span> <span style=\"background-color:rgba(135,206,250,0.1625);\">but</span> <span style=\"background-color:rgba(135,206,250,0.075);\">we</span> <span style=\"background-color:rgba(135,206,250,0.1625);\">wish</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">the</span> <span style=\"background-color:rgba(135,206,250,0.125);\">subscriptions</span> <span style=\"background-color:rgba(135,206,250,0.09999999999999999);\">were</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">more</span> <span style=\"background-color:rgba(135,206,250,0.15);\">accessible</span> <span style=\"background-color:rgba(135,206,250,0.15);\">to</span> <span style=\"background-color:rgba(135,206,250,0.08750000000000001);\">small</span> <span style=\"background-color:rgba(135,206,250,0.25);\">startups</span> <span style=\"background-color:rgba(135,206,250,0.5125);\">.</span><br> <span style=\"background-color:rgba(180,180,180,0.43333333333333335);\">Importance 0.39</span> <span style=\"background-color:rgba(135,206,250,0.09999999999999999);\">we</span> <span style=\"background-color:rgba(135,206,250,0.08750000000000001);\">are</span> <span style=\"background-color:rgba(135,206,250,0.18749999999999997);\">great</span> <span style=\"background-color:rgba(135,206,250,0.3375);\">fans</span> <span style=\"background-color:rgba(135,206,250,0.4875);\">of</span> <span style=\"background-color:rgba(135,206,250,0.4875);\">slack</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">,</span> <span style=\"background-color:rgba(135,206,250,0.11249999999999999);\">but</span> <span style=\"background-color:rgba(135,206,250,0.024999999999999998);\">we</span> <span style=\"background-color:rgba(135,206,250,0.049999999999999996);\">wish</span> <span style=\"background-color:rgba(135,206,250,0.024999999999999998);\">the</span> <span style=\"background-color:rgba(135,206,250,0.11249999999999999);\">subscriptions</span> <span style=\"background-color:rgba(135,206,250,0.024999999999999998);\">were</span> <span style=\"background-color:rgba(135,206,250,0.024999999999999998);\">more</span> <span style=\"background-color:rgba(135,206,250,0.024999999999999998);\">accessible</span> <span style=\"background-color:rgba(135,206,250,0.024999999999999998);\">to</span> <span style=\"background-color:rgba(135,206,250,0.012499999999999999);\">small</span> <span style=\"background-color:rgba(135,206,250,0.0625);\">startups</span> <span style=\"background-color:rgba(135,206,250,0.0375);\">.</span><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heeOqqYFLMXJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNEqJSl9LMa1",
        "outputId": "5475389c-7e52-44d4-b9da-1c33442c530e"
      },
      "source": [
        "import aspect_based_sentiment_analysis as absa\n",
        "help(absa.models)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module aspect_based_sentiment_analysis.models in aspect_based_sentiment_analysis:\n",
            "\n",
            "NAME\n",
            "    aspect_based_sentiment_analysis.models\n",
            "\n",
            "CLASSES\n",
            "    abc.ABC(builtins.object)\n",
            "        ABSClassifier(tensorflow.python.keras.engine.training.Model, abc.ABC)\n",
            "            BertABSClassifier(ABSClassifier, transformers.modeling_tf_bert.TFBertPreTrainedModel)\n",
            "    tensorflow.python.keras.engine.training.Model(tensorflow.python.keras.engine.base_layer.Layer, tensorflow.python.keras.utils.version_utils.ModelVersionSelector)\n",
            "        ABSClassifier(tensorflow.python.keras.engine.training.Model, abc.ABC)\n",
            "            BertABSClassifier(ABSClassifier, transformers.modeling_tf_bert.TFBertPreTrainedModel)\n",
            "    transformers.configuration_bert.BertConfig(transformers.configuration_utils.PretrainedConfig)\n",
            "        BertABSCConfig\n",
            "    \n",
            "    class ABSClassifier(tensorflow.python.keras.engine.training.Model, abc.ABC)\n",
            "     |  The model's aim is to classify the sentiment. The model contains the\n",
            "     |  fine-tuned language model, which holds most parameters. The classifier\n",
            "     |  itself is a tiny linear layer on top of a language model.\n",
            "     |  \n",
            "     |  We use the BERT language model, because we can benefit from the BERT's\n",
            "     |  next-sentence prediction and formulate the task as the sequence-pair\n",
            "     |  classification. Each example is described as one sequence in the format:\n",
            "     |  \"[CLS] text subtokens [SEP] aspect subtokens [SEP]\". The relation between\n",
            "     |  the text and aspect is encoded into the CLS token. The classifier just\n",
            "     |  makes a linear transformation of the final special CLS token representation.\n",
            "     |  The pipeline applies the softmax to get distribution over sentiment classes.\n",
            "     |  \n",
            "     |  Note how to train a model. We start with the original BERT version as a\n",
            "     |  basis, and we divide the training into two stages. Firstly, due to the\n",
            "     |  fact that the BERT is pretrained on dry Wikipedia texts, we wish to bias\n",
            "     |  language model towards more informal language or a specific domain. To do\n",
            "     |  so, we select texts close to the target domain and do the self-supervised\n",
            "     |  **language model** post-training. The routine is the same as for the\n",
            "     |  pre-training, but we need carefully set up optimization parameters.\n",
            "     |  Secondly, we do regular supervised training. We train the whole model\n",
            "     |  using a labeled dataset to classify a sentiment.\n",
            "     |  \n",
            "     |  Please note that the package contains the submodule `absa.training`. You\n",
            "     |  can find there complete routines to tune or train either the language\n",
            "     |  model or the classifier. Check out examples on the package website.\n",
            "     |  \n",
            "     |  References:\n",
            "     |      [BERT: Pre-training of Deep Bidirectional Transformers for Language\n",
            "     |      Understanding](https://arxiv.org/abs/1810.04805)\n",
            "     |      [Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing\n",
            "     |      Auxiliary Sentence](http://arxiv.org/abs/1903.09588)\n",
            "     |      [BERT Post-Training for Review Reading Comprehension and Aspect-based\n",
            "     |      Sentiment Analysis](http://arxiv.org/abs/1904.02232)\n",
            "     |      [Adapt or Get Left Behind: Domain Adaptation through BERT Language\n",
            "     |      Model Finetuning for Aspect-Target Sentiment Classification]\n",
            "     |      (http://arxiv.org/abs/1908.11860)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      ABSClassifier\n",
            "     |      tensorflow.python.keras.engine.training.Model\n",
            "     |      tensorflow.python.keras.engine.base_layer.Layer\n",
            "     |      tensorflow.python.module.module.Module\n",
            "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            "     |      tensorflow.python.training.tracking.base.Trackable\n",
            "     |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
            "     |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
            "     |      abc.ABC\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  call(self, token_ids:tensorflow.python.framework.ops.Tensor, attention_mask:tensorflow.python.framework.ops.Tensor=None, token_type_ids:tensorflow.python.framework.ops.Tensor=None, training:bool=False, **bert_kwargs) -> Tuple[tensorflow.python.framework.ops.Tensor, Tuple[tensorflow.python.framework.ops.Tensor, ...], Tuple[tensorflow.python.framework.ops.Tensor, ...]]\n",
            "     |      Perform the sentiment classification. We formulate the task as the\n",
            "     |      sequence-pair classification. Each example is described as one\n",
            "     |      sequence in the format:\n",
            "     |          \"[CLS] text subtokens [SEP] aspect subtokens [SEP]\".\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      token_ids\n",
            "     |          Indices of input sequence subtokens in the vocabulary.\n",
            "     |      attention_mask\n",
            "     |          Bool mask used to avoid performing attention on padding token\n",
            "     |          indices in a batch (this is not related with masks from the\n",
            "     |          language modeling task).\n",
            "     |      token_type_ids\n",
            "     |          Segment token indices to indicate first and second portions\n",
            "     |          of the inputs, zeros and ones.\n",
            "     |      training\n",
            "     |          Whether to activate a dropout (True) during training or\n",
            "     |          to de-activate them (False) for evaluation.\n",
            "     |      bert_kwargs\n",
            "     |          Auxiliary parameters which we forward directly to\n",
            "     |          the **transformers** language model implementation.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      logits\n",
            "     |          The classifier final outputs.\n",
            "     |      hidden_states\n",
            "     |          Tuple of tensors: one for the output of the embeddings and one\n",
            "     |          for the output of each layer.\n",
            "     |      attentions\n",
            "     |          Tuple of tensors: Attentions weights after the attention softmax,\n",
            "     |          used to compute the weighted average in the self-attention heads.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __abstractmethods__ = frozenset({'call'})\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  __init__(self, *args, **kwargs)\n",
            "     |  \n",
            "     |  __setattr__(self, name, value)\n",
            "     |      Support self.foo = trackable syntax.\n",
            "     |  \n",
            "     |  build(self, input_shape)\n",
            "     |      Builds the model based on input shapes received.\n",
            "     |      \n",
            "     |      This is to be used for subclassed models, which do not know at instantiation\n",
            "     |      time what their inputs look like.\n",
            "     |      \n",
            "     |      This method only exists for users who want to call `model.build()` in a\n",
            "     |      standalone way (as a substitute for calling the model on real data to\n",
            "     |      build it). It will never be called by the framework (and thus it will\n",
            "     |      never throw unexpected errors in an unrelated workflow).\n",
            "     |      \n",
            "     |      Args:\n",
            "     |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
            "     |           are tuples, integers, or TensorShapes.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        ValueError:\n",
            "     |          1. In case of invalid user-provided data (not of type tuple,\n",
            "     |             list, or TensorShape).\n",
            "     |          2. If the model requires call arguments that are agnostic\n",
            "     |             to the input shapes (positional or kwarg in call signature).\n",
            "     |          3. If not all layers were properly built.\n",
            "     |          4. If float type inputs are not supported within the layers.\n",
            "     |      \n",
            "     |        In each of these cases, the user should build their model by calling it\n",
            "     |        on real tensor data.\n",
            "     |  \n",
            "     |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, **kwargs)\n",
            "     |      Configures the model for training.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            "     |            `tf.keras.optimizers`.\n",
            "     |          loss: String (name of objective function), objective function or\n",
            "     |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
            "     |            function is any callable with the signature `loss = fn(y_true,\n",
            "     |            y_pred)`, where y_true = ground truth values with shape =\n",
            "     |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
            "     |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
            "     |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
            "     |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
            "     |            used and reduction is set to NONE, return value has the shape\n",
            "     |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
            "     |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
            "     |            use a different loss on each output by passing a dictionary or a list\n",
            "     |            of losses. The loss value that will be minimized by the model will\n",
            "     |            then be the sum of all individual losses.\n",
            "     |          metrics: List of metrics to be evaluated by the model during training\n",
            "     |            and testing. Each of this can be a string (name of a built-in\n",
            "     |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
            "     |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
            "     |            function is any callable with the signature `result = fn(y_true,\n",
            "     |            y_pred)`. To specify different metrics for different outputs of a\n",
            "     |            multi-output model, you could also pass a dictionary, such as\n",
            "     |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
            "     |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
            "     |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
            "     |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            "     |                strings 'accuracy' or 'acc', we convert this to one of\n",
            "     |                `tf.keras.metrics.BinaryAccuracy`,\n",
            "     |                `tf.keras.metrics.CategoricalAccuracy`,\n",
            "     |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
            "     |                function used and the model output shape. We do a similar\n",
            "     |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
            "     |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
            "     |            (Python floats) to weight the loss contributions of different model\n",
            "     |            outputs. The loss value that will be minimized by the model will then\n",
            "     |            be the *weighted sum* of all individual losses, weighted by the\n",
            "     |            `loss_weights` coefficients.\n",
            "     |              If a list, it is expected to have a 1:1 mapping to the model's\n",
            "     |                outputs. If a dict, it is expected to map output names (strings)\n",
            "     |                to scalar coefficients.\n",
            "     |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            "     |            sample_weight or class_weight during training and testing.\n",
            "     |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
            "     |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
            "     |            this as `None` unless your `Model` cannot be run inside a\n",
            "     |            `tf.function`.\n",
            "     |          **kwargs: Any additional arguments. Supported arguments:\n",
            "     |              - `experimental_steps_per_execution`: Int. The number of batches to\n",
            "     |                run during each `tf.function` call. Running multiple batches\n",
            "     |                inside a single `tf.function` call can greatly improve performance\n",
            "     |                on TPUs or small models with a large Python overhead. Note that if\n",
            "     |                this value is set to `N`, `Callback.on_batch` methods will only be\n",
            "     |                called every `N` batches. This currently defaults to `1`. At most,\n",
            "     |                one full epoch will be run each execution. If a number larger than\n",
            "     |                the size of the epoch is passed, the execution will be truncated\n",
            "     |                to the size of the epoch.\n",
            "     |              - `sample_weight_mode` for backward compatibility.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: In case of invalid arguments for\n",
            "     |              `optimizer`, `loss` or `metrics`.\n",
            "     |  \n",
            "     |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
            "     |      Returns the loss value & metrics values for the model in test mode.\n",
            "     |      \n",
            "     |      Computation is done in batches (see the `batch_size` arg.)\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors,\n",
            "     |              if the model has named inputs.\n",
            "     |            - A `tf.data` dataset. Should return a tuple\n",
            "     |              of either `(inputs, targets)` or\n",
            "     |              `(inputs, targets, sample_weights)`.\n",
            "     |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            "     |              or `(inputs, targets, sample_weights)`.\n",
            "     |            A more detailed description of unpacking behavior for iterator types\n",
            "     |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            "     |            for iterator-like inputs` section of `Model.fit`.\n",
            "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "     |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            "     |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            "     |            should not be specified (since targets will be obtained from the\n",
            "     |            iterator/dataset).\n",
            "     |          batch_size: Integer or `None`. Number of samples per batch of\n",
            "     |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
            "     |            specify the `batch_size` if your data is in the form of a dataset,\n",
            "     |            generators, or `keras.utils.Sequence` instances (since they generate\n",
            "     |            batches).\n",
            "     |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            "     |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            "     |            used for weighting the loss function. You can either pass a flat (1D)\n",
            "     |            Numpy array with the same length as the input samples\n",
            "     |              (1:1 mapping between weights and samples), or in the case of\n",
            "     |                temporal data, you can pass a 2D array with shape `(samples,\n",
            "     |                sequence_length)`, to apply a different weight to every timestep\n",
            "     |                of every sample. This argument is not supported when `x` is a\n",
            "     |                dataset, instead pass sample weights as the third element of `x`.\n",
            "     |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            "     |            before declaring the evaluation round finished. Ignored with the\n",
            "     |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            "     |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            "     |            argument is not supported with array inputs.\n",
            "     |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            "     |            callbacks to apply during evaluation. See\n",
            "     |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "     |            input only. Maximum size for the generator queue. If unspecified,\n",
            "     |            `max_queue_size` will default to 10.\n",
            "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "     |            only. Maximum number of processes to spin up when using process-based\n",
            "     |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
            "     |            execute the generator on the main thread.\n",
            "     |          use_multiprocessing: Boolean. Used for generator or\n",
            "     |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "     |            threading. If unspecified, `use_multiprocessing` will default to\n",
            "     |            `False`. Note that because this implementation relies on\n",
            "     |            multiprocessing, you should not pass non-picklable arguments to the\n",
            "     |            generator as they can't be passed easily to children processes.\n",
            "     |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "     |            with each key being the name of the metric. If `False`, they are\n",
            "     |            returned as a list.\n",
            "     |      \n",
            "     |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            "     |      `Model.fit`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Scalar test loss (if the model has a single output and no metrics)\n",
            "     |          or list of scalars (if the model has multiple outputs\n",
            "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            "     |          the display labels for the scalar outputs.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
            "     |          ValueError: in case of invalid arguments.\n",
            "     |  \n",
            "     |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            "     |      Evaluates the model on a data generator. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use Model.evaluate, which supports generators.\n",
            "     |      \n",
            "     |      DEPRECATED:\n",
            "     |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            "     |        to use this endpoint.\n",
            "     |  \n",
            "     |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            "     |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors,\n",
            "     |              if the model has named inputs.\n",
            "     |            - A `tf.data` dataset. Should return a tuple\n",
            "     |              of either `(inputs, targets)` or\n",
            "     |              `(inputs, targets, sample_weights)`.\n",
            "     |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            "     |              or `(inputs, targets, sample_weights)`.\n",
            "     |            A more detailed description of unpacking behavior for iterator types\n",
            "     |            (Dataset, generator, Sequence) is given below.\n",
            "     |          y: Target data. Like the input data `x`,\n",
            "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            "     |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            "     |            or `keras.utils.Sequence` instance, `y` should\n",
            "     |            not be specified (since targets will be obtained from `x`).\n",
            "     |          batch_size: Integer or `None`.\n",
            "     |              Number of samples per gradient update.\n",
            "     |              If unspecified, `batch_size` will default to 32.\n",
            "     |              Do not specify the `batch_size` if your data is in the\n",
            "     |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            "     |              (since they generate batches).\n",
            "     |          epochs: Integer. Number of epochs to train the model.\n",
            "     |              An epoch is an iteration over the entire `x` and `y`\n",
            "     |              data provided.\n",
            "     |              Note that in conjunction with `initial_epoch`,\n",
            "     |              `epochs` is to be understood as \"final epoch\".\n",
            "     |              The model is not trained for a number of iterations\n",
            "     |              given by `epochs`, but merely until the epoch\n",
            "     |              of index `epochs` is reached.\n",
            "     |          verbose: 0, 1, or 2. Verbosity mode.\n",
            "     |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            "     |              Note that the progress bar is not particularly useful when\n",
            "     |              logged to a file, so verbose=2 is recommended when not running\n",
            "     |              interactively (eg, in a production environment).\n",
            "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            "     |              List of callbacks to apply during training.\n",
            "     |              See `tf.keras.callbacks`.\n",
            "     |          validation_split: Float between 0 and 1.\n",
            "     |              Fraction of the training data to be used as validation data.\n",
            "     |              The model will set apart this fraction of the training data,\n",
            "     |              will not train on it, and will evaluate\n",
            "     |              the loss and any model metrics\n",
            "     |              on this data at the end of each epoch.\n",
            "     |              The validation data is selected from the last samples\n",
            "     |              in the `x` and `y` data provided, before shuffling. This argument is\n",
            "     |              not supported when `x` is a dataset, generator or\n",
            "     |             `keras.utils.Sequence` instance.\n",
            "     |          validation_data: Data on which to evaluate\n",
            "     |              the loss and any model metrics at the end of each epoch.\n",
            "     |              The model will not be trained on this data. Thus, note the fact\n",
            "     |              that the validation loss of data provided using `validation_split`\n",
            "     |              or `validation_data` is not affected by regularization layers like\n",
            "     |              noise and dropuout.\n",
            "     |              `validation_data` will override `validation_split`.\n",
            "     |              `validation_data` could be:\n",
            "     |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
            "     |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
            "     |                - dataset\n",
            "     |              For the first two cases, `batch_size` must be provided.\n",
            "     |              For the last case, `validation_steps` could be provided.\n",
            "     |              Note that `validation_data` does not support all the data types that\n",
            "     |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
            "     |          shuffle: Boolean (whether to shuffle the training data\n",
            "     |              before each epoch) or str (for 'batch'). This argument is ignored\n",
            "     |              when `x` is a generator. 'batch' is a special option for dealing\n",
            "     |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            "     |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            "     |          class_weight: Optional dictionary mapping class indices (integers)\n",
            "     |              to a weight (float) value, used for weighting the loss function\n",
            "     |              (during training only).\n",
            "     |              This can be useful to tell the model to\n",
            "     |              \"pay more attention\" to samples from\n",
            "     |              an under-represented class.\n",
            "     |          sample_weight: Optional Numpy array of weights for\n",
            "     |              the training samples, used for weighting the loss function\n",
            "     |              (during training only). You can either pass a flat (1D)\n",
            "     |              Numpy array with the same length as the input samples\n",
            "     |              (1:1 mapping between weights and samples),\n",
            "     |              or in the case of temporal data,\n",
            "     |              you can pass a 2D array with shape\n",
            "     |              `(samples, sequence_length)`,\n",
            "     |              to apply a different weight to every timestep of every sample. This\n",
            "     |              argument is not supported when `x` is a dataset, generator, or\n",
            "     |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
            "     |              as the third element of `x`.\n",
            "     |          initial_epoch: Integer.\n",
            "     |              Epoch at which to start training\n",
            "     |              (useful for resuming a previous training run).\n",
            "     |          steps_per_epoch: Integer or `None`.\n",
            "     |              Total number of steps (batches of samples)\n",
            "     |              before declaring one epoch finished and starting the\n",
            "     |              next epoch. When training with input tensors such as\n",
            "     |              TensorFlow data tensors, the default `None` is equal to\n",
            "     |              the number of samples in your dataset divided by\n",
            "     |              the batch size, or 1 if that cannot be determined. If x is a\n",
            "     |              `tf.data` dataset, and 'steps_per_epoch'\n",
            "     |              is None, the epoch will run until the input dataset is exhausted.\n",
            "     |              When passing an infinitely repeating dataset, you must specify the\n",
            "     |              `steps_per_epoch` argument. This argument is not supported with\n",
            "     |              array inputs.\n",
            "     |          validation_steps: Only relevant if `validation_data` is provided and\n",
            "     |              is a `tf.data` dataset. Total number of steps (batches of\n",
            "     |              samples) to draw before stopping when performing validation\n",
            "     |              at the end of every epoch. If 'validation_steps' is None, validation\n",
            "     |              will run until the `validation_data` dataset is exhausted. In the\n",
            "     |              case of an infinitely repeated dataset, it will run into an\n",
            "     |              infinite loop. If 'validation_steps' is specified and only part of\n",
            "     |              the dataset will be consumed, the evaluation will start from the\n",
            "     |              beginning of the dataset at each epoch. This ensures that the same\n",
            "     |              validation samples are used every time.\n",
            "     |          validation_batch_size: Integer or `None`.\n",
            "     |              Number of samples per validation batch.\n",
            "     |              If unspecified, will default to `batch_size`.\n",
            "     |              Do not specify the `validation_batch_size` if your data is in the\n",
            "     |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            "     |              (since they generate batches).\n",
            "     |          validation_freq: Only relevant if validation data is provided. Integer\n",
            "     |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
            "     |              If an integer, specifies how many training epochs to run before a\n",
            "     |              new validation run is performed, e.g. `validation_freq=2` runs\n",
            "     |              validation every 2 epochs. If a Container, specifies the epochs on\n",
            "     |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
            "     |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
            "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "     |              input only. Maximum size for the generator queue.\n",
            "     |              If unspecified, `max_queue_size` will default to 10.\n",
            "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "     |              only. Maximum number of processes to spin up\n",
            "     |              when using process-based threading. If unspecified, `workers`\n",
            "     |              will default to 1. If 0, will execute the generator on the main\n",
            "     |              thread.\n",
            "     |          use_multiprocessing: Boolean. Used for generator or\n",
            "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
            "     |              `False`. Note that because this implementation relies on\n",
            "     |              multiprocessing, you should not pass non-picklable arguments to\n",
            "     |              the generator as they can't be passed easily to children processes.\n",
            "     |      \n",
            "     |      Unpacking behavior for iterator-like inputs:\n",
            "     |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            "     |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            "     |        yield not only features (x) but optionally targets (y) and sample weights.\n",
            "     |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
            "     |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
            "     |        second and third elements will be used for y and sample_weight\n",
            "     |        respectively. Any other type provided will be wrapped in a length one\n",
            "     |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
            "     |        should still adhere to the top-level tuple structure.\n",
            "     |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            "     |        features, targets, and weights from the keys of a single dict.\n",
            "     |          A notable unsupported data type is the namedtuple. The reason is that\n",
            "     |        it behaves like both an ordered datatype (tuple) and a mapping\n",
            "     |        datatype (dict). So given a namedtuple of the form:\n",
            "     |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            "     |        it is ambiguous whether to reverse the order of the elements when\n",
            "     |        interpreting the value. Even worse is a tuple of the form:\n",
            "     |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            "     |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
            "     |        and sample_weight or passed through as a single element to `x`. As a\n",
            "     |        result the data processing code will simply raise a ValueError if it\n",
            "     |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A `History` object. Its `History.history` attribute is\n",
            "     |          a record of training loss values and metrics values\n",
            "     |          at successive epochs, as well as validation loss values\n",
            "     |          and validation metrics values (if applicable).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: 1. If the model was never compiled or,\n",
            "     |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            "     |      \n",
            "     |          ValueError: In case of mismatch between the provided input data\n",
            "     |              and what the model expects.\n",
            "     |  \n",
            "     |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            "     |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use Model.fit, which supports generators.\n",
            "     |      \n",
            "     |      DEPRECATED:\n",
            "     |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            "     |        this endpoint.\n",
            "     |  \n",
            "     |  get_config(self)\n",
            "     |      Returns the config of the layer.\n",
            "     |      \n",
            "     |      A layer config is a Python dictionary (serializable)\n",
            "     |      containing the configuration of a layer.\n",
            "     |      The same layer can be reinstantiated later\n",
            "     |      (without its trained weights) from this configuration.\n",
            "     |      \n",
            "     |      The config of a layer does not include connectivity\n",
            "     |      information, nor the layer class name. These are handled\n",
            "     |      by `Network` (one layer of abstraction above).\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Python dictionary.\n",
            "     |  \n",
            "     |  get_layer(self, name=None, index=None)\n",
            "     |      Retrieves a layer based on either its name (unique) or index.\n",
            "     |      \n",
            "     |      If `name` and `index` are both provided, `index` will take precedence.\n",
            "     |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          name: String, name of layer.\n",
            "     |          index: Integer, index of layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A layer instance.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: In case of invalid layer name or index.\n",
            "     |  \n",
            "     |  get_weights(self)\n",
            "     |      Retrieves the weights of the model.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A flat list of Numpy arrays.\n",
            "     |  \n",
            "     |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
            "     |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
            "     |      \n",
            "     |      If `by_name` is False weights are loaded based on the network's\n",
            "     |      topology. This means the architecture should be the same as when the weights\n",
            "     |      were saved.  Note that layers that don't have weights are not taken into\n",
            "     |      account in the topological ordering, so adding or removing layers is fine as\n",
            "     |      long as they don't have weights.\n",
            "     |      \n",
            "     |      If `by_name` is True, weights are loaded into layers only if they share the\n",
            "     |      same name. This is useful for fine-tuning or transfer-learning models where\n",
            "     |      some of the layers have changed.\n",
            "     |      \n",
            "     |      Only topological loading (`by_name=False`) is supported when loading weights\n",
            "     |      from the TensorFlow format. Note that topological loading differs slightly\n",
            "     |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
            "     |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
            "     |      TensorFlow format loads based on the object-local names of attributes to\n",
            "     |      which layers are assigned in the `Model`'s constructor.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          filepath: String, path to the weights file to load. For weight files in\n",
            "     |              TensorFlow format, this is the file prefix (the same as was passed\n",
            "     |              to `save_weights`).\n",
            "     |          by_name: Boolean, whether to load weights by name or by topological\n",
            "     |              order. Only topological loading is supported for weight files in\n",
            "     |              TensorFlow format.\n",
            "     |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
            "     |              a mismatch in the number of weights, or a mismatch in the shape of\n",
            "     |              the weight (only valid when `by_name=True`).\n",
            "     |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            "     |              options for loading weights.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          When loading a weight file in TensorFlow format, returns the same status\n",
            "     |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
            "     |          ops are run automatically as soon as the network is built (on first call\n",
            "     |          for user-defined classes inheriting from `Model`, immediately if it is\n",
            "     |          already built).\n",
            "     |      \n",
            "     |          When loading weights in HDF5 format, returns `None`.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ImportError: If h5py is not available and the weight file is in HDF5\n",
            "     |              format.\n",
            "     |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
            "     |            `False`.\n",
            "     |  \n",
            "     |  make_predict_function(self)\n",
            "     |      Creates a function that executes one step of inference.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom inference logic.\n",
            "     |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            "     |      \n",
            "     |      Typically, this method directly controls `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            "     |      logic to `Model.predict_step`.\n",
            "     |      \n",
            "     |      This function is cached the first time `Model.predict` or\n",
            "     |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            "     |      `Model.compile` is called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Function. The function created by this method should accept a\n",
            "     |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            "     |  \n",
            "     |  make_test_function(self)\n",
            "     |      Creates a function that executes one step of evaluation.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom evaluation logic.\n",
            "     |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            "     |      \n",
            "     |      Typically, this method directly controls `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            "     |      logic to `Model.test_step`.\n",
            "     |      \n",
            "     |      This function is cached the first time `Model.evaluate` or\n",
            "     |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            "     |      `Model.compile` is called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Function. The function created by this method should accept a\n",
            "     |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            "     |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            "     |  \n",
            "     |  make_train_function(self)\n",
            "     |      Creates a function that executes one step of training.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom training logic.\n",
            "     |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            "     |      \n",
            "     |      Typically, this method directly controls `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            "     |      logic to `Model.train_step`.\n",
            "     |      \n",
            "     |      This function is cached the first time `Model.fit` or\n",
            "     |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            "     |      `Model.compile` is called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Function. The function created by this method should accept a\n",
            "     |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            "     |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            "     |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            "     |  \n",
            "     |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            "     |      Generates output predictions for the input samples.\n",
            "     |      \n",
            "     |      Computation is done in batches. This method is designed for performance in\n",
            "     |      large scale inputs. For small amount of inputs that fit in one batch,\n",
            "     |      directly using `__call__` is recommended for faster execution, e.g.,\n",
            "     |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            "     |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
            "     |      inference. Also, note the fact that test loss is not affected by\n",
            "     |      regularization layers like noise and dropout.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input samples. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A `tf.data` dataset.\n",
            "     |            - A generator or `keras.utils.Sequence` instance.\n",
            "     |            A more detailed description of unpacking behavior for iterator types\n",
            "     |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            "     |            for iterator-like inputs` section of `Model.fit`.\n",
            "     |          batch_size: Integer or `None`.\n",
            "     |              Number of samples per batch.\n",
            "     |              If unspecified, `batch_size` will default to 32.\n",
            "     |              Do not specify the `batch_size` if your data is in the\n",
            "     |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            "     |              (since they generate batches).\n",
            "     |          verbose: Verbosity mode, 0 or 1.\n",
            "     |          steps: Total number of steps (batches of samples)\n",
            "     |              before declaring the prediction round finished.\n",
            "     |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            "     |              dataset and `steps` is None, `predict` will\n",
            "     |              run until the input dataset is exhausted.\n",
            "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            "     |              List of callbacks to apply during prediction.\n",
            "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "     |              input only. Maximum size for the generator queue.\n",
            "     |              If unspecified, `max_queue_size` will default to 10.\n",
            "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "     |              only. Maximum number of processes to spin up when using\n",
            "     |              process-based threading. If unspecified, `workers` will default\n",
            "     |              to 1. If 0, will execute the generator on the main thread.\n",
            "     |          use_multiprocessing: Boolean. Used for generator or\n",
            "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
            "     |              `False`. Note that because this implementation relies on\n",
            "     |              multiprocessing, you should not pass non-picklable arguments to\n",
            "     |              the generator as they can't be passed easily to children processes.\n",
            "     |      \n",
            "     |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            "     |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            "     |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            "     |      three methods.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Numpy array(s) of predictions.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
            "     |          ValueError: In case of mismatch between the provided\n",
            "     |              input data and the model's expectations,\n",
            "     |              or in case a stateful model receives a number of samples\n",
            "     |              that is not a multiple of the batch size.\n",
            "     |  \n",
            "     |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            "     |      Generates predictions for the input samples from a data generator. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use Model.predict, which supports generators.\n",
            "     |      \n",
            "     |      DEPRECATED:\n",
            "     |        `Model.predict` now supports generators, so there is no longer any need\n",
            "     |        to use this endpoint.\n",
            "     |  \n",
            "     |  predict_on_batch(self, x)\n",
            "     |      Returns predictions for a single batch of samples.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            "     |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            "     |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Numpy array(s) of predictions.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
            "     |          ValueError: In case of mismatch between given number of inputs and\n",
            "     |            expectations of the model.\n",
            "     |  \n",
            "     |  predict_step(self, data)\n",
            "     |      The logic for one inference step.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom inference logic.\n",
            "     |      This method is called by `Model.make_predict_function`.\n",
            "     |      \n",
            "     |      This method should contain the mathemetical logic for one step of inference.\n",
            "     |      This typically includes the forward pass.\n",
            "     |      \n",
            "     |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings), should be left to\n",
            "     |      `Model.make_predict_function`, which can also be overridden.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        data: A nested structure of `Tensor`s.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        The result of one inference step, typically the output of calling the\n",
            "     |        `Model` on data.\n",
            "     |  \n",
            "     |  reset_metrics(self)\n",
            "     |      Resets the state of all the metrics in the model.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            "     |      \n",
            "     |      >>> x = np.random.random((2, 3))\n",
            "     |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            "     |      >>> _ = model.fit(x, y, verbose=0)\n",
            "     |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            "     |      \n",
            "     |      >>> model.reset_metrics()\n",
            "     |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            "     |  \n",
            "     |  reset_states(self)\n",
            "     |  \n",
            "     |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
            "     |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
            "     |      \n",
            "     |      The savefile includes:\n",
            "     |      \n",
            "     |      - The model architecture, allowing to re-instantiate the model.\n",
            "     |      - The model weights.\n",
            "     |      - The state of the optimizer, allowing to resume training\n",
            "     |          exactly where you left off.\n",
            "     |      \n",
            "     |      This allows you to save the entirety of the state of a model\n",
            "     |      in a single file.\n",
            "     |      \n",
            "     |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
            "     |      The model returned by `load_model` is a compiled model ready to be used\n",
            "     |      (unless the saved model was never compiled in the first place).\n",
            "     |      \n",
            "     |      Models built with the Sequential and Functional API can be saved to both the\n",
            "     |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
            "     |      SavedModel format.\n",
            "     |      \n",
            "     |      Note that the model weights may have different scoped names after being\n",
            "     |      loaded. Scoped names include the model/layer names, such as\n",
            "     |      `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n",
            "     |       access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
            "     |              model.\n",
            "     |          overwrite: Whether to silently overwrite any existing file at the\n",
            "     |              target location, or provide the user with a manual prompt.\n",
            "     |          include_optimizer: If True, save optimizer's state together.\n",
            "     |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
            "     |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
            "     |              and 'h5' in TF 1.X.\n",
            "     |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
            "     |              'tf' format only. Please see the `signatures` argument in\n",
            "     |              `tf.saved_model.save` for details.\n",
            "     |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
            "     |              options for saving to SavedModel.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      from keras.models import load_model\n",
            "     |      \n",
            "     |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
            "     |      del model  # deletes the existing model\n",
            "     |      \n",
            "     |      # returns a compiled model\n",
            "     |      # identical to the previous one\n",
            "     |      model = load_model('my_model.h5')\n",
            "     |      ```\n",
            "     |  \n",
            "     |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            "     |      Saves all layer weights.\n",
            "     |      \n",
            "     |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            "     |      argument.\n",
            "     |      \n",
            "     |      When saving in HDF5 format, the weight file has:\n",
            "     |        - `layer_names` (attribute), a list of strings\n",
            "     |            (ordered names of model layers).\n",
            "     |        - For every layer, a `group` named `layer.name`\n",
            "     |            - For every such layer group, a group attribute `weight_names`,\n",
            "     |                a list of strings\n",
            "     |                (ordered names of weights tensor of the layer).\n",
            "     |            - For every weight in the layer, a dataset\n",
            "     |                storing the weight value, named after the weight tensor.\n",
            "     |      \n",
            "     |      When saving in TensorFlow format, all objects referenced by the network are\n",
            "     |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            "     |      instances or `Optimizer` instances assigned to object attributes. For\n",
            "     |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            "     |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            "     |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            "     |      `Layer` instances must be assigned to object attributes, typically in the\n",
            "     |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            "     |      `tf.keras.Model` for details.\n",
            "     |      \n",
            "     |      While the formats are the same, do not mix `save_weights` and\n",
            "     |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            "     |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            "     |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            "     |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            "     |      `save_weights` for training checkpoints.\n",
            "     |      \n",
            "     |      The TensorFlow format matches objects and variables by starting at a root\n",
            "     |      object, `self` for `save_weights`, and greedily matching attribute\n",
            "     |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            "     |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            "     |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            "     |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            "     |      the `Model`'s variables. See the [guide to training\n",
            "     |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
            "     |      on the TensorFlow format.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          filepath: String or PathLike, path to the file to save the weights to.\n",
            "     |              When saving in TensorFlow format, this is the prefix used for\n",
            "     |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
            "     |              suffix causes weights to be saved in HDF5 format.\n",
            "     |          overwrite: Whether to silently overwrite any existing file at the\n",
            "     |              target location, or provide the user with a manual prompt.\n",
            "     |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            "     |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            "     |              `None` defaults to 'tf'.\n",
            "     |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            "     |              options for saving weights.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ImportError: If h5py is not available when attempting to save in HDF5\n",
            "     |              format.\n",
            "     |          ValueError: For invalid/unknown format arguments.\n",
            "     |  \n",
            "     |  summary(self, line_length=None, positions=None, print_fn=None)\n",
            "     |      Prints a string summary of the network.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          line_length: Total length of printed lines\n",
            "     |              (e.g. set this to adapt the display to different\n",
            "     |              terminal window sizes).\n",
            "     |          positions: Relative or absolute positions of log elements\n",
            "     |              in each line. If not provided,\n",
            "     |              defaults to `[.33, .55, .67, 1.]`.\n",
            "     |          print_fn: Print function to use. Defaults to `print`.\n",
            "     |              It will be called on each line of the summary.\n",
            "     |              You can set it to a custom function\n",
            "     |              in order to capture the string summary.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: if `summary()` is called before the model is built.\n",
            "     |  \n",
            "     |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            "     |      Test the model on a single batch of samples.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            "     |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            "     |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors, if\n",
            "     |            the model has named inputs.\n",
            "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "     |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            "     |          sample_weight: Optional array of the same length as x, containing\n",
            "     |            weights to apply to the model's loss for each sample. In the case of\n",
            "     |            temporal data, you can pass a 2D array with shape (samples,\n",
            "     |            sequence_length), to apply a different weight to every timestep of\n",
            "     |            every sample.\n",
            "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
            "     |            batches.\n",
            "     |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "     |            with each key being the name of the metric. If `False`, they are\n",
            "     |            returned as a list.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Scalar test loss (if the model has a single output and no metrics)\n",
            "     |          or list of scalars (if the model has multiple outputs\n",
            "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            "     |          the display labels for the scalar outputs.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
            "     |          ValueError: In case of invalid user-provided arguments.\n",
            "     |  \n",
            "     |  test_step(self, data)\n",
            "     |      The logic for one evaluation step.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom evaluation logic.\n",
            "     |      This method is called by `Model.make_test_function`.\n",
            "     |      \n",
            "     |      This function should contain the mathemetical logic for one step of\n",
            "     |      evaluation.\n",
            "     |      This typically includes the forward pass, loss calculation, and metrics\n",
            "     |      updates.\n",
            "     |      \n",
            "     |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings), should be left to\n",
            "     |      `Model.make_test_function`, which can also be overridden.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        data: A nested structure of `Tensor`s.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A `dict` containing values that will be passed to\n",
            "     |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            "     |        values of the `Model`'s metrics are returned.\n",
            "     |  \n",
            "     |  to_json(self, **kwargs)\n",
            "     |      Returns a JSON string containing the network configuration.\n",
            "     |      \n",
            "     |      To load a network from a JSON save file, use\n",
            "     |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          **kwargs: Additional keyword arguments\n",
            "     |              to be passed to `json.dumps()`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A JSON string.\n",
            "     |  \n",
            "     |  to_yaml(self, **kwargs)\n",
            "     |      Returns a yaml string containing the network configuration.\n",
            "     |      \n",
            "     |      To load a network from a yaml save file, use\n",
            "     |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            "     |      \n",
            "     |      `custom_objects` should be a dictionary mapping\n",
            "     |      the names of custom losses / layers / etc to the corresponding\n",
            "     |      functions / classes.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          **kwargs: Additional keyword arguments\n",
            "     |              to be passed to `yaml.dump()`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A YAML string.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ImportError: if yaml module is not found.\n",
            "     |  \n",
            "     |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            "     |      Runs a single gradient update on a single batch of data.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |                (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |                (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors,\n",
            "     |                if the model has named inputs.\n",
            "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "     |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            "     |          sample_weight: Optional array of the same length as x, containing\n",
            "     |            weights to apply to the model's loss for each sample. In the case of\n",
            "     |            temporal data, you can pass a 2D array with shape (samples,\n",
            "     |            sequence_length), to apply a different weight to every timestep of\n",
            "     |            every sample.\n",
            "     |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            "     |            weight (float) to apply to the model's loss for the samples from this\n",
            "     |            class during training. This can be useful to tell the model to \"pay\n",
            "     |            more attention\" to samples from an under-represented class.\n",
            "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
            "     |            batches.\n",
            "     |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "     |            with each key being the name of the metric. If `False`, they are\n",
            "     |            returned as a list.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Scalar training loss\n",
            "     |          (if the model has a single output and no metrics)\n",
            "     |          or list of scalars (if the model has multiple outputs\n",
            "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            "     |          the display labels for the scalar outputs.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
            "     |        ValueError: In case of invalid user-provided arguments.\n",
            "     |  \n",
            "     |  train_step(self, data)\n",
            "     |      The logic for one training step.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom training logic.\n",
            "     |      This method is called by `Model.make_train_function`.\n",
            "     |      \n",
            "     |      This method should contain the mathemetical logic for one step of training.\n",
            "     |      This typically includes the forward pass, loss calculation, backpropagation,\n",
            "     |      and metric updates.\n",
            "     |      \n",
            "     |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings), should be left to\n",
            "     |      `Model.make_train_function`, which can also be overridden.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        data: A nested structure of `Tensor`s.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A `dict` containing values that will be passed to\n",
            "     |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            "     |        values of the `Model`'s metrics are returned. Example:\n",
            "     |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  from_config(config, custom_objects=None) from abc.ABCMeta\n",
            "     |      Creates a layer from its config.\n",
            "     |      \n",
            "     |      This method is the reverse of `get_config`,\n",
            "     |      capable of instantiating the same layer from the config\n",
            "     |      dictionary. It does not handle layer connectivity\n",
            "     |      (handled by Network), nor weights (handled by `set_weights`).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          config: A Python dictionary, typically the\n",
            "     |              output of get_config.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A layer instance.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  __new__(cls, *args, **kwargs)\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  distribute_strategy\n",
            "     |      The `tf.distribute.Strategy` this model was created under.\n",
            "     |  \n",
            "     |  layers\n",
            "     |  \n",
            "     |  metrics\n",
            "     |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
            "     |      \n",
            "     |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
            "     |      has been trained/evaluated on actual data.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            "     |      >>> [m.name for m in model.metrics]\n",
            "     |      []\n",
            "     |      \n",
            "     |      >>> x = np.random.random((2, 3))\n",
            "     |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            "     |      >>> model.fit(x, y)\n",
            "     |      >>> [m.name for m in model.metrics]\n",
            "     |      ['loss', 'mae']\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            "     |      >>> output_1 = d(inputs)\n",
            "     |      >>> output_2 = d(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(\n",
            "     |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            "     |      >>> model.add_metric(\n",
            "     |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            "     |      >>> model.fit(x, (y, y))\n",
            "     |      >>> [m.name for m in model.metrics]\n",
            "     |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            "     |      'out_1_acc', 'mean']\n",
            "     |  \n",
            "     |  metrics_names\n",
            "     |      Returns the model's display labels for all outputs.\n",
            "     |      \n",
            "     |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            "     |      trained/evaluated on actual data.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            "     |      >>> model.metrics_names\n",
            "     |      []\n",
            "     |      \n",
            "     |      >>> x = np.random.random((2, 3))\n",
            "     |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            "     |      >>> model.fit(x, y)\n",
            "     |      >>> model.metrics_names\n",
            "     |      ['loss', 'mae']\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            "     |      >>> output_1 = d(inputs)\n",
            "     |      >>> output_2 = d(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(\n",
            "     |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            "     |      >>> model.fit(x, (y, y))\n",
            "     |      >>> model.metrics_names\n",
            "     |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            "     |      'out_1_acc']\n",
            "     |  \n",
            "     |  non_trainable_weights\n",
            "     |      List of all non-trainable weights tracked by this layer.\n",
            "     |      \n",
            "     |      Non-trainable weights are *not* updated during training. They are expected\n",
            "     |      to be updated manually in `call()`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of non-trainable variables.\n",
            "     |  \n",
            "     |  run_eagerly\n",
            "     |      Settable attribute indicating whether the model should run eagerly.\n",
            "     |      \n",
            "     |      Running eagerly means that your model will be run step by step,\n",
            "     |      like Python code. Your model might run slower, but it should become easier\n",
            "     |      for you to debug it by stepping into individual layer calls.\n",
            "     |      \n",
            "     |      By default, we will attempt to compile your model to a static graph to\n",
            "     |      deliver the best execution performance.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Boolean, whether the model should run eagerly.\n",
            "     |  \n",
            "     |  state_updates\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "     |      \n",
            "     |      Returns the `updates` from all layers that are stateful.\n",
            "     |      \n",
            "     |      This is useful for separating training updates and\n",
            "     |      state updates, e.g. when we need to update a layer's internal state\n",
            "     |      during prediction.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A list of update ops.\n",
            "     |  \n",
            "     |  trainable_weights\n",
            "     |      List of all trainable weights tracked by this layer.\n",
            "     |      \n",
            "     |      Trainable weights are updated via gradient descent during training.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of trainable variables.\n",
            "     |  \n",
            "     |  weights\n",
            "     |      Returns the list of all layer variables/weights.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of variables.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            "     |  \n",
            "     |  __call__(self, *args, **kwargs)\n",
            "     |      Wraps `call`, applying pre- and post-processing steps.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        *args: Positional arguments to be passed to `self.call`.\n",
            "     |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Output tensor(s).\n",
            "     |      \n",
            "     |      Note:\n",
            "     |        - The following optional keyword arguments are reserved for specific uses:\n",
            "     |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            "     |            whether the `call` is meant for training or inference.\n",
            "     |          * `mask`: Boolean input mask.\n",
            "     |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            "     |          layers do), its default value will be set to the mask generated\n",
            "     |          for `inputs` by the previous layer (if `input` did come from\n",
            "     |          a layer that generated a corresponding mask, i.e. if it came from\n",
            "     |          a Keras layer with masking support.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            "     |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            "     |  \n",
            "     |  __delattr__(self, name)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  add_loss(self, losses, **kwargs)\n",
            "     |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            "     |      \n",
            "     |      Some losses (for instance, activity regularization losses) may be dependent\n",
            "     |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            "     |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            "     |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            "     |      of dependencies.\n",
            "     |      \n",
            "     |      This method can be used inside a subclassed layer or model's `call`\n",
            "     |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      class MyLayer(tf.keras.layers.Layer):\n",
            "     |        def call(self, inputs):\n",
            "     |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            "     |          return inputs\n",
            "     |      ```\n",
            "     |      \n",
            "     |      This method can also be called directly on a Functional Model during\n",
            "     |      construction. In this case, any loss Tensors passed to this Model must\n",
            "     |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            "     |      losses become part of the model's topology and are tracked in `get_config`.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      # Activity regularization.\n",
            "     |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            "     |      ```\n",
            "     |      \n",
            "     |      If this is not the case for your loss (if, for example, your loss references\n",
            "     |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            "     |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            "     |      topology since they can't be serialized.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      d = tf.keras.layers.Dense(10)\n",
            "     |      x = d(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      # Weight regularization.\n",
            "     |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            "     |          may also be zero-argument callables which create a loss tensor.\n",
            "     |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            "     |          Accepted values:\n",
            "     |            inputs - Deprecated, will be automatically inferred.\n",
            "     |  \n",
            "     |  add_metric(self, value, name=None, **kwargs)\n",
            "     |      Adds metric tensor to the layer.\n",
            "     |      \n",
            "     |      This method can be used inside the `call()` method of a subclassed layer\n",
            "     |      or model.\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            "     |        def __init__(self):\n",
            "     |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            "     |          self.mean = metrics_module.Mean(name='metric_1')\n",
            "     |      \n",
            "     |        def call(self, inputs):\n",
            "     |          self.add_metric(self.mean(x))\n",
            "     |          self.add_metric(math_ops.reduce_sum(x), name='metric_2')\n",
            "     |          return inputs\n",
            "     |      ```\n",
            "     |      \n",
            "     |      This method can also be called directly on a Functional Model during\n",
            "     |      construction. In this case, any tensor passed to this Model must\n",
            "     |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            "     |      metrics become part of the model's topology and are tracked when you\n",
            "     |      save the model via `save()`.\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            "     |      Functional Model, as shown in the example below, is not supported. This is\n",
            "     |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Args:\n",
            "     |        value: Metric tensor.\n",
            "     |        name: String metric name.\n",
            "     |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            "     |          Accepted values:\n",
            "     |          `aggregation` - When the `value` tensor provided is not the result of\n",
            "     |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            "     |          using a `keras.Metric.Mean`.\n",
            "     |  \n",
            "     |  add_update(self, updates, inputs=None)\n",
            "     |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
            "     |      \n",
            "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      `inputs` is now automatically inferred\n",
            "     |      \n",
            "     |      Weight updates (for instance, the updates of the moving mean and variance\n",
            "     |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            "     |      when calling a layer. Hence, when reusing the same layer on\n",
            "     |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            "     |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            "     |      of dependencies.\n",
            "     |      \n",
            "     |      This call is ignored when eager execution is enabled (in that case, variable\n",
            "     |      updates are run on the fly and thus do not need to be tracked for later\n",
            "     |      execution).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            "     |          that returns an update op. A zero-arg callable should be passed in\n",
            "     |          order to disable running the updates by setting `trainable=False`\n",
            "     |          on this Layer, when executing in Eager mode.\n",
            "     |        inputs: Deprecated, will be automatically inferred.\n",
            "     |  \n",
            "     |  add_variable(self, *args, **kwargs)\n",
            "     |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.add_weight` method instead.\n",
            "     |  \n",
            "     |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
            "     |      Adds a new variable to the layer.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        name: Variable name.\n",
            "     |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            "     |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
            "     |        initializer: Initializer instance (callable).\n",
            "     |        regularizer: Regularizer instance (callable).\n",
            "     |        trainable: Boolean, whether the variable should be part of the layer's\n",
            "     |          \"trainable_variables\" (e.g. variables, biases)\n",
            "     |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            "     |          Note that `trainable` cannot be `True` if `synchronization`\n",
            "     |          is set to `ON_READ`.\n",
            "     |        constraint: Constraint instance (callable).\n",
            "     |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
            "     |        use_resource: Whether to use `ResourceVariable`.\n",
            "     |        synchronization: Indicates when a distributed a variable will be\n",
            "     |          aggregated. Accepted values are constants defined in the class\n",
            "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            "     |          `AUTO` and the current `DistributionStrategy` chooses\n",
            "     |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            "     |          `trainable` must not be set to `True`.\n",
            "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            "     |          Accepted values are constants defined in the class\n",
            "     |          `tf.VariableAggregation`.\n",
            "     |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            "     |          `collections`, `experimental_autocast` and `caching_device`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
            "     |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
            "     |        instance is returned.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called with partitioned variable regularization and\n",
            "     |          eager execution is enabled.\n",
            "     |        ValueError: When giving unsupported dtype and no initializer or when\n",
            "     |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            "     |  \n",
            "     |  apply(self, inputs, *args, **kwargs)\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.__call__` method instead.\n",
            "     |      \n",
            "     |      This is an alias of `self.__call__`.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        inputs: Input tensor(s).\n",
            "     |        *args: additional positional arguments to be passed to `self.call`.\n",
            "     |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Output tensor(s).\n",
            "     |  \n",
            "     |  compute_mask(self, inputs, mask=None)\n",
            "     |      Computes an output mask tensor.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          inputs: Tensor or list of tensors.\n",
            "     |          mask: Tensor or list of tensors.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          None or a tensor (or list of tensors,\n",
            "     |              one per output tensor of the layer).\n",
            "     |  \n",
            "     |  compute_output_shape(self, input_shape)\n",
            "     |      Computes the output shape of the layer.\n",
            "     |      \n",
            "     |      If the layer has not been built, this method will call `build` on the\n",
            "     |      layer. This assumes that the layer will later be used with inputs that\n",
            "     |      match the input shape provided here.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          input_shape: Shape tuple (tuple of integers)\n",
            "     |              or list of shape tuples (one per output tensor of the layer).\n",
            "     |              Shape tuples can include None for free dimensions,\n",
            "     |              instead of an integer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          An input shape tuple.\n",
            "     |  \n",
            "     |  compute_output_signature(self, input_signature)\n",
            "     |      Compute the output tensor signature of the layer based on the inputs.\n",
            "     |      \n",
            "     |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            "     |      and dtype information for a tensor. This method allows layers to provide\n",
            "     |      output dtype information if it is different from the input dtype.\n",
            "     |      For any layer that doesn't implement this function,\n",
            "     |      the framework will fall back to use `compute_output_shape`, and will\n",
            "     |      assume that the output dtype matches the input dtype.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            "     |          objects, describing a candidate input for the layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            "     |          how the layer would transform the provided input.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            "     |  \n",
            "     |  count_params(self)\n",
            "     |      Count the total number of scalars composing the weights.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          An integer count.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: if the layer isn't yet built\n",
            "     |            (in which case its weights aren't yet defined).\n",
            "     |  \n",
            "     |  get_input_at(self, node_index)\n",
            "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_input_mask_at(self, node_index)\n",
            "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A mask tensor\n",
            "     |          (or list of tensors if the layer has multiple inputs).\n",
            "     |  \n",
            "     |  get_input_shape_at(self, node_index)\n",
            "     |      Retrieves the input shape(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A shape tuple\n",
            "     |          (or list of shape tuples if the layer has multiple inputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_losses_for(self, inputs)\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.losses` instead.\n",
            "     |      \n",
            "     |      Retrieves losses relevant to a specific set of inputs.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        inputs: Input tensor or list/tuple of input tensors.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        List of loss tensors of the layer that depend on `inputs`.\n",
            "     |  \n",
            "     |  get_output_at(self, node_index)\n",
            "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_output_mask_at(self, node_index)\n",
            "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A mask tensor\n",
            "     |          (or list of tensors if the layer has multiple outputs).\n",
            "     |  \n",
            "     |  get_output_shape_at(self, node_index)\n",
            "     |      Retrieves the output shape(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A shape tuple\n",
            "     |          (or list of shape tuples if the layer has multiple outputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_updates_for(self, inputs)\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.updates` instead.\n",
            "     |      \n",
            "     |      Retrieves updates relevant to a specific set of inputs.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        inputs: Input tensor or list/tuple of input tensors.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        List of update ops of the layer that depend on `inputs`.\n",
            "     |  \n",
            "     |  set_weights(self, weights)\n",
            "     |      Sets the weights of the layer, from Numpy arrays.\n",
            "     |      \n",
            "     |      The weights of a layer represent the state of the layer. This function\n",
            "     |      sets the weight values from numpy arrays. The weight values should be\n",
            "     |      passed in the order they are created by the layer. Note that the layer's\n",
            "     |      weights must be instantiated before calling this function by calling\n",
            "     |      the layer.\n",
            "     |      \n",
            "     |      For example, a Dense layer returns a list of two values-- per-output\n",
            "     |      weights and the bias value. These can be used to set the weights of another\n",
            "     |      Dense layer:\n",
            "     |      \n",
            "     |      >>> a = tf.keras.layers.Dense(1,\n",
            "     |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            "     |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            "     |      >>> a.get_weights()\n",
            "     |      [array([[1.],\n",
            "     |             [1.],\n",
            "     |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            "     |      >>> b = tf.keras.layers.Dense(1,\n",
            "     |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            "     |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            "     |      >>> b.get_weights()\n",
            "     |      [array([[2.],\n",
            "     |             [2.],\n",
            "     |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            "     |      >>> b.set_weights(a.get_weights())\n",
            "     |      >>> b.get_weights()\n",
            "     |      [array([[1.],\n",
            "     |             [1.],\n",
            "     |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          weights: a list of Numpy arrays. The number\n",
            "     |              of arrays and their shape must match\n",
            "     |              number of the dimensions of the weights\n",
            "     |              of the layer (i.e. it should match the\n",
            "     |              output of `get_weights`).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: If the provided weights list does not match the\n",
            "     |              layer's specifications.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            "     |  \n",
            "     |  activity_regularizer\n",
            "     |      Optional regularizer function for the output of this layer.\n",
            "     |  \n",
            "     |  dtype\n",
            "     |      Dtype used by the weights of the layer, set in the constructor.\n",
            "     |  \n",
            "     |  dynamic\n",
            "     |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            "     |  \n",
            "     |  inbound_nodes\n",
            "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            "     |  \n",
            "     |  input\n",
            "     |      Retrieves the input tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one input,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Input tensor or list of input tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |        AttributeError: If no inbound nodes are found.\n",
            "     |  \n",
            "     |  input_mask\n",
            "     |      Retrieves the input mask tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one inbound node,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Input mask tensor (potentially None) or list of input\n",
            "     |          mask tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer is connected to\n",
            "     |          more than one incoming layers.\n",
            "     |  \n",
            "     |  input_shape\n",
            "     |      Retrieves the input shape(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one input,\n",
            "     |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            "     |      have the same shape.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Input shape, as an integer shape tuple\n",
            "     |          (or list of shape tuples, one tuple per input tensor).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer has no defined input_shape.\n",
            "     |          RuntimeError: if called in Eager mode.\n",
            "     |  \n",
            "     |  input_spec\n",
            "     |      `InputSpec` instance(s) describing the input format for this layer.\n",
            "     |      \n",
            "     |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            "     |      the layer to run input compatibility checks when it is called.\n",
            "     |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            "     |      of rank 4. As such, you can set, in `__init__()`:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Now, if you try to call the layer on an input that isn't rank 4\n",
            "     |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            "     |      error:\n",
            "     |      \n",
            "     |      ```\n",
            "     |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            "     |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Input checks that can be specified via `input_spec` include:\n",
            "     |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            "     |      - Shape\n",
            "     |      - Rank (ndim)\n",
            "     |      - Dtype\n",
            "     |      \n",
            "     |      For more information, see `tf.keras.layers.InputSpec`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            "     |  \n",
            "     |  losses\n",
            "     |      List of losses added using the `add_loss()` API.\n",
            "     |      \n",
            "     |      Variable regularization tensors are created when this property is accessed,\n",
            "     |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            "     |      propagate gradients back to the corresponding variables.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            "     |      ...   def call(self, inputs):\n",
            "     |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            "     |      ...     return inputs\n",
            "     |      >>> l = MyLayer()\n",
            "     |      >>> l(np.ones((10, 1)))\n",
            "     |      >>> l.losses\n",
            "     |      [1.0]\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            "     |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      >>> model = tf.keras.Model(inputs, outputs)\n",
            "     |      >>> # Activity regularization.\n",
            "     |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            "     |      >>> model.losses\n",
            "     |      [<tf.Tensor 'Abs:0' shape=() dtype=float32>]\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            "     |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            "     |      >>> x = d(inputs)\n",
            "     |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      >>> model = tf.keras.Model(inputs, outputs)\n",
            "     |      >>> # Weight regularization.\n",
            "     |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            "     |      >>> model.losses\n",
            "     |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of tensors.\n",
            "     |  \n",
            "     |  name\n",
            "     |      Name of the layer (string), set in the constructor.\n",
            "     |  \n",
            "     |  non_trainable_variables\n",
            "     |  \n",
            "     |  outbound_nodes\n",
            "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            "     |  \n",
            "     |  output\n",
            "     |      Retrieves the output tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one output,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Output tensor or list of output tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        AttributeError: if the layer is connected to more than one incoming\n",
            "     |          layers.\n",
            "     |        RuntimeError: if called in Eager mode.\n",
            "     |  \n",
            "     |  output_mask\n",
            "     |      Retrieves the output mask tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one inbound node,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Output mask tensor (potentially None) or list of output\n",
            "     |          mask tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer is connected to\n",
            "     |          more than one incoming layers.\n",
            "     |  \n",
            "     |  output_shape\n",
            "     |      Retrieves the output shape(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has one output,\n",
            "     |      or if all outputs have the same shape.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Output shape, as an integer shape tuple\n",
            "     |          (or list of shape tuples, one tuple per output tensor).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer has no defined output shape.\n",
            "     |          RuntimeError: if called in Eager mode.\n",
            "     |  \n",
            "     |  stateful\n",
            "     |  \n",
            "     |  supports_masking\n",
            "     |      Whether this layer supports computing a mask using `compute_mask`.\n",
            "     |  \n",
            "     |  trainable\n",
            "     |  \n",
            "     |  trainable_variables\n",
            "     |      Sequence of trainable variables owned by this module and its submodules.\n",
            "     |      \n",
            "     |      Note: this method uses reflection to find variables on the current instance\n",
            "     |      and submodules. For performance reasons you may wish to cache the result\n",
            "     |      of calling this method if you don't expect the return value to change.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A sequence of variables for the current module (sorted by attribute\n",
            "     |        name) followed by variables from all submodules recursively (breadth\n",
            "     |        first).\n",
            "     |  \n",
            "     |  updates\n",
            "     |      DEPRECATED FUNCTION\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "     |  \n",
            "     |  variables\n",
            "     |      Returns the list of all layer variables/weights.\n",
            "     |      \n",
            "     |      Alias of `self.weights`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of variables.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            "     |  \n",
            "     |  with_name_scope(method) from abc.ABCMeta\n",
            "     |      Decorator to automatically enter the module name scope.\n",
            "     |      \n",
            "     |      >>> class MyModule(tf.Module):\n",
            "     |      ...   @tf.Module.with_name_scope\n",
            "     |      ...   def __call__(self, x):\n",
            "     |      ...     if not hasattr(self, 'w'):\n",
            "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            "     |      ...     return tf.matmul(x, self.w)\n",
            "     |      \n",
            "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            "     |      names included the module name:\n",
            "     |      \n",
            "     |      >>> mod = MyModule()\n",
            "     |      >>> mod(tf.ones([1, 2]))\n",
            "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            "     |      >>> mod.w\n",
            "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            "     |      numpy=..., dtype=float32)>\n",
            "     |      \n",
            "     |      Args:\n",
            "     |        method: The method to wrap.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        The original method wrapped such that it enters the module's name scope.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            "     |  \n",
            "     |  name_scope\n",
            "     |      Returns a `tf.name_scope` instance for this class.\n",
            "     |  \n",
            "     |  submodules\n",
            "     |      Sequence of all sub-modules.\n",
            "     |      \n",
            "     |      Submodules are modules which are properties of this module, or found as\n",
            "     |      properties of modules which are properties of this module (and so on).\n",
            "     |      \n",
            "     |      >>> a = tf.Module()\n",
            "     |      >>> b = tf.Module()\n",
            "     |      >>> c = tf.Module()\n",
            "     |      >>> a.b = b\n",
            "     |      >>> b.c = c\n",
            "     |      >>> list(a.submodules) == [b, c]\n",
            "     |      True\n",
            "     |      >>> list(b.submodules) == [c]\n",
            "     |      True\n",
            "     |      >>> list(c.submodules) == []\n",
            "     |      True\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A sequence of all submodules.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "    \n",
            "    class BertABSCConfig(transformers.configuration_bert.BertConfig)\n",
            "     |  This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a\n",
            "     |  :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,\n",
            "     |  defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration\n",
            "     |  to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.\n",
            "     |  \n",
            "     |  Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model\n",
            "     |  outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.\n",
            "     |  \n",
            "     |  \n",
            "     |  Args:\n",
            "     |      vocab_size (:obj:`int`, `optional`, defaults to 30522):\n",
            "     |          Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the\n",
            "     |          :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or\n",
            "     |          :class:`~transformers.TFBertModel`.\n",
            "     |      hidden_size (:obj:`int`, `optional`, defaults to 768):\n",
            "     |          Dimensionality of the encoder layers and the pooler layer.\n",
            "     |      num_hidden_layers (:obj:`int`, `optional`, defaults to 12):\n",
            "     |          Number of hidden layers in the Transformer encoder.\n",
            "     |      num_attention_heads (:obj:`int`, `optional`, defaults to 12):\n",
            "     |          Number of attention heads for each attention layer in the Transformer encoder.\n",
            "     |      intermediate_size (:obj:`int`, `optional`, defaults to 3072):\n",
            "     |          Dimensionality of the \"intermediate\" (often named feed-forward) layer in the Transformer encoder.\n",
            "     |      hidden_act (:obj:`str` or :obj:`Callable`, `optional`, defaults to :obj:`\"gelu\"`):\n",
            "     |          The non-linear activation function (function or string) in the encoder and pooler. If string,\n",
            "     |          :obj:`\"gelu\"`, :obj:`\"relu\"`, :obj:`\"silu\"` and :obj:`\"gelu_new\"` are supported.\n",
            "     |      hidden_dropout_prob (:obj:`float`, `optional`, defaults to 0.1):\n",
            "     |          The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.\n",
            "     |      attention_probs_dropout_prob (:obj:`float`, `optional`, defaults to 0.1):\n",
            "     |          The dropout ratio for the attention probabilities.\n",
            "     |      max_position_embeddings (:obj:`int`, `optional`, defaults to 512):\n",
            "     |          The maximum sequence length that this model might ever be used with. Typically set this to something large\n",
            "     |          just in case (e.g., 512 or 1024 or 2048).\n",
            "     |      type_vocab_size (:obj:`int`, `optional`, defaults to 2):\n",
            "     |          The vocabulary size of the :obj:`token_type_ids` passed when calling :class:`~transformers.BertModel` or\n",
            "     |          :class:`~transformers.TFBertModel`.\n",
            "     |      initializer_range (:obj:`float`, `optional`, defaults to 0.02):\n",
            "     |          The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
            "     |      layer_norm_eps (:obj:`float`, `optional`, defaults to 1e-12):\n",
            "     |          The epsilon used by the layer normalization layers.\n",
            "     |      gradient_checkpointing (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |          If True, use gradient checkpointing to save memory at the expense of slower backward pass.\n",
            "     |  \n",
            "     |  Examples::\n",
            "     |  \n",
            "     |      >>> from transformers import BertModel, BertConfig\n",
            "     |  \n",
            "     |      >>> # Initializing a BERT bert-base-uncased style configuration\n",
            "     |      >>> configuration = BertConfig()\n",
            "     |  \n",
            "     |      >>> # Initializing a model from the bert-base-uncased style configuration\n",
            "     |      >>> model = BertModel(configuration)\n",
            "     |  \n",
            "     |      >>> # Accessing the model configuration\n",
            "     |      >>> configuration = model.config\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      BertABSCConfig\n",
            "     |      transformers.configuration_bert.BertConfig\n",
            "     |      transformers.configuration_utils.PretrainedConfig\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, num_polarities:int=3, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from transformers.configuration_bert.BertConfig:\n",
            "     |  \n",
            "     |  model_type = 'bert'\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from transformers.configuration_utils.PretrainedConfig:\n",
            "     |  \n",
            "     |  __eq__(self, other)\n",
            "     |      Return self==value.\n",
            "     |  \n",
            "     |  __repr__(self)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  save_pretrained(self, save_directory:str)\n",
            "     |      Save a configuration object to the directory ``save_directory``, so that it can be re-loaded using the\n",
            "     |      :func:`~transformers.PretrainedConfig.from_pretrained` class method.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          save_directory (:obj:`str`):\n",
            "     |              Directory where the configuration JSON file will be saved (will be created if it does not exist).\n",
            "     |  \n",
            "     |  to_dict(self) -> Dict[str, Any]\n",
            "     |      Serializes this instance to a Python dictionary.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`Dict[str, Any]`: Dictionary of all the attributes that make up this configuration instance.\n",
            "     |  \n",
            "     |  to_diff_dict(self) -> Dict[str, Any]\n",
            "     |      Removes all attributes from config which correspond to the default config attributes for better readability and\n",
            "     |      serializes to a Python dictionary.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`Dict[str, Any]`: Dictionary of all the attributes that make up this configuration instance,\n",
            "     |  \n",
            "     |  to_json_file(self, json_file_path:str, use_diff:bool=True)\n",
            "     |      Save this instance to a JSON file.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          json_file_path (:obj:`str`):\n",
            "     |              Path to the JSON file in which this configuration instance's parameters will be saved.\n",
            "     |          use_diff (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
            "     |              If set to ``True``, only the difference between the config instance and the default\n",
            "     |              ``PretrainedConfig()`` is serialized to JSON file.\n",
            "     |  \n",
            "     |  to_json_string(self, use_diff:bool=True) -> str\n",
            "     |      Serializes this instance to a JSON string.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          use_diff (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
            "     |              If set to ``True``, only the difference between the config instance and the default\n",
            "     |              ``PretrainedConfig()`` is serialized to JSON string.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`str`: String containing all the attributes that make up this configuration instance in JSON format.\n",
            "     |  \n",
            "     |  update(self, config_dict:Dict[str, Any])\n",
            "     |      Updates attributes of this class with attributes from ``config_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          config_dict (:obj:`Dict[str, Any]`): Dictionary of attributes that shall be updated for this class.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from transformers.configuration_utils.PretrainedConfig:\n",
            "     |  \n",
            "     |  from_dict(config_dict:Dict[str, Any], **kwargs) -> 'PretrainedConfig' from builtins.type\n",
            "     |      Instantiates a :class:`~transformers.PretrainedConfig` from a Python dictionary of parameters.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          config_dict (:obj:`Dict[str, Any]`):\n",
            "     |              Dictionary that will be used to instantiate the configuration object. Such a dictionary can be\n",
            "     |              retrieved from a pretrained checkpoint by leveraging the\n",
            "     |              :func:`~transformers.PretrainedConfig.get_config_dict` method.\n",
            "     |          kwargs (:obj:`Dict[str, Any]`):\n",
            "     |              Additional parameters from which to initialize the configuration object.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`PretrainedConfig`: The configuration object instantiated from those parameters.\n",
            "     |  \n",
            "     |  from_json_file(json_file:str) -> 'PretrainedConfig' from builtins.type\n",
            "     |      Instantiates a :class:`~transformers.PretrainedConfig` from the path to a JSON file of parameters.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          json_file (:obj:`str`):\n",
            "     |              Path to the JSON file containing the parameters.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`PretrainedConfig`: The configuration object instantiated from that JSON file.\n",
            "     |  \n",
            "     |  from_pretrained(pretrained_model_name_or_path:str, **kwargs) -> 'PretrainedConfig' from builtins.type\n",
            "     |      Instantiate a :class:`~transformers.PretrainedConfig` (or a derived class) from a pretrained model\n",
            "     |      configuration.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          pretrained_model_name_or_path (:obj:`str`):\n",
            "     |              This can be either:\n",
            "     |      \n",
            "     |              - the `shortcut name` of a pretrained model configuration to load from cache or download, e.g.,\n",
            "     |                ``bert-base-uncased``.\n",
            "     |              - the `identifier name` of a pretrained model configuration that was uploaded to our S3 by any user,\n",
            "     |                e.g., ``dbmdz/bert-base-german-cased``.\n",
            "     |              - a path to a `directory` containing a configuration file saved using the\n",
            "     |                :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g., ``./my_model_directory/``.\n",
            "     |              - a path or url to a saved configuration JSON `file`, e.g.,\n",
            "     |                ``./my_model_directory/configuration.json``.\n",
            "     |          cache_dir (:obj:`str`, `optional`):\n",
            "     |              Path to a directory in which a downloaded pretrained model configuration should be cached if the\n",
            "     |              standard cache should not be used.\n",
            "     |          force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to force to (re-)download the configuration files and override the cached versions if\n",
            "     |              they exist.\n",
            "     |          resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to delete incompletely received file. Attempts to resume the download if such a file\n",
            "     |              exists.\n",
            "     |          proxies (:obj:`Dict[str, str]`, `optional`):\n",
            "     |              A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',\n",
            "     |              'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n",
            "     |          revision(:obj:`str`, `optional`, defaults to :obj:`\"main\"`):\n",
            "     |              The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
            "     |              git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any\n",
            "     |              identifier allowed by git.\n",
            "     |          return_unused_kwargs (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              If :obj:`False`, then this function returns just the final configuration object.\n",
            "     |      \n",
            "     |              If :obj:`True`, then this functions returns a :obj:`Tuple(config, unused_kwargs)` where `unused_kwargs`\n",
            "     |              is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e.,\n",
            "     |              the part of ``kwargs`` which has not been used to update ``config`` and is otherwise ignored.\n",
            "     |          kwargs (:obj:`Dict[str, Any]`, `optional`):\n",
            "     |              The values in kwargs of any keys which are configuration attributes will be used to override the loaded\n",
            "     |              values. Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled\n",
            "     |              by the ``return_unused_kwargs`` keyword parameter.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`PretrainedConfig`: The configuration object instantiated from this pretrained model.\n",
            "     |      \n",
            "     |      Examples::\n",
            "     |      \n",
            "     |          # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n",
            "     |          # derived class: BertConfig\n",
            "     |          config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n",
            "     |          config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n",
            "     |          config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n",
            "     |          config = BertConfig.from_pretrained('bert-base-uncased', output_attentions=True, foo=False)\n",
            "     |          assert config.output_attentions == True\n",
            "     |          config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attentions=True,\n",
            "     |                                                             foo=False, return_unused_kwargs=True)\n",
            "     |          assert config.output_attentions == True\n",
            "     |          assert unused_kwargs == {'foo': False}\n",
            "     |  \n",
            "     |  get_config_dict(pretrained_model_name_or_path:str, **kwargs) -> Tuple[Dict[str, Any], Dict[str, Any]] from builtins.type\n",
            "     |      From a ``pretrained_model_name_or_path``, resolve to a dictionary of parameters, to be used for instantiating a\n",
            "     |      :class:`~transformers.PretrainedConfig` using ``from_dict``.\n",
            "     |      \n",
            "     |      Parameters:\n",
            "     |          pretrained_model_name_or_path (:obj:`str`):\n",
            "     |              The identifier of the pre-trained checkpoint from which we want the dictionary of parameters.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`Tuple[Dict, Dict]`: The dictionary(ies) that will be used to instantiate the configuration object.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from transformers.configuration_utils.PretrainedConfig:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  name_or_path\n",
            "     |  \n",
            "     |  num_labels\n",
            "     |      :obj:`int`: The number of labels for classification models.\n",
            "     |  \n",
            "     |  use_return_dict\n",
            "     |      :obj:`bool`: Whether or not return :class:`~transformers.file_utils.ModelOutput` instead of tuples.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from transformers.configuration_utils.PretrainedConfig:\n",
            "     |  \n",
            "     |  __annotations__ = {'is_composition': <class 'bool'>, 'model_type': <cl...\n",
            "     |  \n",
            "     |  __hash__ = None\n",
            "     |  \n",
            "     |  is_composition = False\n",
            "    \n",
            "    class BertABSClassifier(ABSClassifier, transformers.modeling_tf_bert.TFBertPreTrainedModel)\n",
            "     |  The model's aim is to classify the sentiment. The model contains the\n",
            "     |  fine-tuned language model, which holds most parameters. The classifier\n",
            "     |  itself is a tiny linear layer on top of a language model.\n",
            "     |  \n",
            "     |  We use the BERT language model, because we can benefit from the BERT's\n",
            "     |  next-sentence prediction and formulate the task as the sequence-pair\n",
            "     |  classification. Each example is described as one sequence in the format:\n",
            "     |  \"[CLS] text subtokens [SEP] aspect subtokens [SEP]\". The relation between\n",
            "     |  the text and aspect is encoded into the CLS token. The classifier just\n",
            "     |  makes a linear transformation of the final special CLS token representation.\n",
            "     |  The pipeline applies the softmax to get distribution over sentiment classes.\n",
            "     |  \n",
            "     |  Note how to train a model. We start with the original BERT version as a\n",
            "     |  basis, and we divide the training into two stages. Firstly, due to the\n",
            "     |  fact that the BERT is pretrained on dry Wikipedia texts, we wish to bias\n",
            "     |  language model towards more informal language or a specific domain. To do\n",
            "     |  so, we select texts close to the target domain and do the self-supervised\n",
            "     |  **language model** post-training. The routine is the same as for the\n",
            "     |  pre-training, but we need carefully set up optimization parameters.\n",
            "     |  Secondly, we do regular supervised training. We train the whole model\n",
            "     |  using a labeled dataset to classify a sentiment.\n",
            "     |  \n",
            "     |  Please note that the package contains the submodule `absa.training`. You\n",
            "     |  can find there complete routines to tune or train either the language\n",
            "     |  model or the classifier. Check out examples on the package website.\n",
            "     |  \n",
            "     |  References:\n",
            "     |      [BERT: Pre-training of Deep Bidirectional Transformers for Language\n",
            "     |      Understanding](https://arxiv.org/abs/1810.04805)\n",
            "     |      [Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing\n",
            "     |      Auxiliary Sentence](http://arxiv.org/abs/1903.09588)\n",
            "     |      [BERT Post-Training for Review Reading Comprehension and Aspect-based\n",
            "     |      Sentiment Analysis](http://arxiv.org/abs/1904.02232)\n",
            "     |      [Adapt or Get Left Behind: Domain Adaptation through BERT Language\n",
            "     |      Model Finetuning for Aspect-Target Sentiment Classification]\n",
            "     |      (http://arxiv.org/abs/1908.11860)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      BertABSClassifier\n",
            "     |      ABSClassifier\n",
            "     |      transformers.modeling_tf_bert.TFBertPreTrainedModel\n",
            "     |      transformers.modeling_tf_utils.TFPreTrainedModel\n",
            "     |      tensorflow.python.keras.engine.training.Model\n",
            "     |      tensorflow.python.keras.engine.base_layer.Layer\n",
            "     |      tensorflow.python.module.module.Module\n",
            "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            "     |      tensorflow.python.training.tracking.base.Trackable\n",
            "     |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
            "     |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
            "     |      abc.ABC\n",
            "     |      transformers.modeling_tf_utils.TFModelUtilsMixin\n",
            "     |      transformers.generation_tf_utils.TFGenerationMixin\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, config:aspect_based_sentiment_analysis.models.BertABSCConfig, **kwargs)\n",
            "     |  \n",
            "     |  call(self, token_ids:tensorflow.python.framework.ops.Tensor, attention_mask:tensorflow.python.framework.ops.Tensor=None, token_type_ids:tensorflow.python.framework.ops.Tensor=None, training:bool=False, **bert_kwargs) -> Tuple[tensorflow.python.framework.ops.Tensor, Tuple[tensorflow.python.framework.ops.Tensor, ...], Tuple[tensorflow.python.framework.ops.Tensor, ...]]\n",
            "     |      Perform the sentiment classification. We formulate the task as the\n",
            "     |      sequence-pair classification. Each example is described as one\n",
            "     |      sequence in the format:\n",
            "     |          \"[CLS] text subtokens [SEP] aspect subtokens [SEP]\".\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      token_ids\n",
            "     |          Indices of input sequence subtokens in the vocabulary.\n",
            "     |      attention_mask\n",
            "     |          Bool mask used to avoid performing attention on padding token\n",
            "     |          indices in a batch (this is not related with masks from the\n",
            "     |          language modeling task).\n",
            "     |      token_type_ids\n",
            "     |          Segment token indices to indicate first and second portions\n",
            "     |          of the inputs, zeros and ones.\n",
            "     |      training\n",
            "     |          Whether to activate a dropout (True) during training or\n",
            "     |          to de-activate them (False) for evaluation.\n",
            "     |      bert_kwargs\n",
            "     |          Auxiliary parameters which we forward directly to\n",
            "     |          the **transformers** language model implementation.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      logits\n",
            "     |          The classifier final outputs.\n",
            "     |      hidden_states\n",
            "     |          Tuple of tensors: one for the output of the embeddings and one\n",
            "     |          for the output of each layer.\n",
            "     |      attentions\n",
            "     |          Tuple of tensors: Attentions weights after the attention softmax,\n",
            "     |          used to compute the weighted average in the self-attention heads.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __abstractmethods__ = frozenset()\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from transformers.modeling_tf_bert.TFBertPreTrainedModel:\n",
            "     |  \n",
            "     |  base_model_prefix = 'bert'\n",
            "     |  \n",
            "     |  config_class = <class 'transformers.configuration_bert.BertConfig'>\n",
            "     |      This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a\n",
            "     |      :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,\n",
            "     |      defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration\n",
            "     |      to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.\n",
            "     |      \n",
            "     |      Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model\n",
            "     |      outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.\n",
            "     |      \n",
            "     |      \n",
            "     |      Args:\n",
            "     |          vocab_size (:obj:`int`, `optional`, defaults to 30522):\n",
            "     |              Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the\n",
            "     |              :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or\n",
            "     |              :class:`~transformers.TFBertModel`.\n",
            "     |          hidden_size (:obj:`int`, `optional`, defaults to 768):\n",
            "     |              Dimensionality of the encoder layers and the pooler layer.\n",
            "     |          num_hidden_layers (:obj:`int`, `optional`, defaults to 12):\n",
            "     |              Number of hidden layers in the Transformer encoder.\n",
            "     |          num_attention_heads (:obj:`int`, `optional`, defaults to 12):\n",
            "     |              Number of attention heads for each attention layer in the Transformer encoder.\n",
            "     |          intermediate_size (:obj:`int`, `optional`, defaults to 3072):\n",
            "     |              Dimensionality of the \"intermediate\" (often named feed-forward) layer in the Transformer encoder.\n",
            "     |          hidden_act (:obj:`str` or :obj:`Callable`, `optional`, defaults to :obj:`\"gelu\"`):\n",
            "     |              The non-linear activation function (function or string) in the encoder and pooler. If string,\n",
            "     |              :obj:`\"gelu\"`, :obj:`\"relu\"`, :obj:`\"silu\"` and :obj:`\"gelu_new\"` are supported.\n",
            "     |          hidden_dropout_prob (:obj:`float`, `optional`, defaults to 0.1):\n",
            "     |              The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.\n",
            "     |          attention_probs_dropout_prob (:obj:`float`, `optional`, defaults to 0.1):\n",
            "     |              The dropout ratio for the attention probabilities.\n",
            "     |          max_position_embeddings (:obj:`int`, `optional`, defaults to 512):\n",
            "     |              The maximum sequence length that this model might ever be used with. Typically set this to something large\n",
            "     |              just in case (e.g., 512 or 1024 or 2048).\n",
            "     |          type_vocab_size (:obj:`int`, `optional`, defaults to 2):\n",
            "     |              The vocabulary size of the :obj:`token_type_ids` passed when calling :class:`~transformers.BertModel` or\n",
            "     |              :class:`~transformers.TFBertModel`.\n",
            "     |          initializer_range (:obj:`float`, `optional`, defaults to 0.02):\n",
            "     |              The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
            "     |          layer_norm_eps (:obj:`float`, `optional`, defaults to 1e-12):\n",
            "     |              The epsilon used by the layer normalization layers.\n",
            "     |          gradient_checkpointing (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              If True, use gradient checkpointing to save memory at the expense of slower backward pass.\n",
            "     |      \n",
            "     |      Examples::\n",
            "     |      \n",
            "     |          >>> from transformers import BertModel, BertConfig\n",
            "     |      \n",
            "     |          >>> # Initializing a BERT bert-base-uncased style configuration\n",
            "     |          >>> configuration = BertConfig()\n",
            "     |      \n",
            "     |          >>> # Initializing a model from the bert-base-uncased style configuration\n",
            "     |          >>> model = BertModel(configuration)\n",
            "     |      \n",
            "     |          >>> # Accessing the model configuration\n",
            "     |          >>> configuration = model.config\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            "     |  \n",
            "     |  get_input_embeddings(self) -> tensorflow.python.keras.engine.base_layer.Layer\n",
            "     |      Returns the model's input embeddings.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`tf.keras.layers.Layer`: A torch module mapping vocabulary to hidden states.\n",
            "     |  \n",
            "     |  get_output_embeddings(self) -> tensorflow.python.keras.engine.base_layer.Layer\n",
            "     |      Returns the model's output embeddings.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`tf.keras.layers.Layer`: A torch module mapping hidden states to vocabulary.\n",
            "     |  \n",
            "     |  prune_heads(self, heads_to_prune)\n",
            "     |      Prunes heads of the base model.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          heads_to_prune (:obj:`Dict[int, List[int]]`):\n",
            "     |              Dictionary with keys being selected layer indices (:obj:`int`) and associated values being the list of\n",
            "     |              heads to prune in said layer (list of :obj:`int`). For instance {1: [0, 2], 2: [2, 3]} will prune heads\n",
            "     |              0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n",
            "     |  \n",
            "     |  resize_token_embeddings(self, new_num_tokens=None) -> tensorflow.python.ops.variables.Variable\n",
            "     |      Resizes input token embeddings matrix of the model if :obj:`new_num_tokens != config.vocab_size`.\n",
            "     |      \n",
            "     |      Takes care of tying weights embeddings afterwards if the model class has a :obj:`tie_weights()` method.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          new_num_tokens (:obj:`int`, `optional`):\n",
            "     |              The number of new tokens in the embedding matrix. Increasing the size will add newly initialized\n",
            "     |              vectors at the end. Reducing the size will remove vectors from the end. If not provided or :obj:`None`,\n",
            "     |              just returns a pointer to the input tokens :obj:`tf.Variable` module of the model wihtout doing\n",
            "     |              anything.\n",
            "     |      \n",
            "     |      Return:\n",
            "     |          :obj:`tf.Variable`: Pointer to the input tokens Embeddings Module of the model.\n",
            "     |  \n",
            "     |  save_pretrained(self, save_directory)\n",
            "     |      Save a model and its configuration file to a directory, so that it can be re-loaded using the\n",
            "     |      :func:`~transformers.TFPreTrainedModel.from_pretrained` class method.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          save_directory (:obj:`str`):\n",
            "     |              Directory to which to save. Will be created if it doesn't exist.\n",
            "     |  \n",
            "     |  set_input_embeddings(self, value)\n",
            "     |      Set model's input embeddings.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          value (:obj:`tf.keras.layers.Layer`):\n",
            "     |              A module mapping vocabulary to hidden states.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            "     |  \n",
            "     |  from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs) from abc.ABCMeta\n",
            "     |      Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.\n",
            "     |      \n",
            "     |      The warning `Weights from XXX not initialized from pretrained model` means that the weights of XXX do not come\n",
            "     |      pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning\n",
            "     |      task.\n",
            "     |      \n",
            "     |      The warning `Weights from XXX not used in YYY` means that the layer XXX is not used by YYY, therefore those\n",
            "     |      weights are discarded.\n",
            "     |      \n",
            "     |      Parameters:\n",
            "     |          pretrained_model_name_or_path (:obj:`str`, `optional`):\n",
            "     |              Can be either:\n",
            "     |      \n",
            "     |                  - A string with the `shortcut name` of a pretrained model to load from cache or download, e.g.,\n",
            "     |                    ``bert-base-uncased``.\n",
            "     |                  - A string with the `identifier name` of a pretrained model that was user-uploaded to our S3, e.g.,\n",
            "     |                    ``dbmdz/bert-base-german-cased``.\n",
            "     |                  - A path to a `directory` containing model weights saved using\n",
            "     |                    :func:`~transformersTF.PreTrainedModel.save_pretrained`, e.g., ``./my_model_directory/``.\n",
            "     |                  - A path or url to a `PyTorch state_dict save file` (e.g, ``./pt_model/pytorch_model.bin``). In\n",
            "     |                    this case, ``from_pt`` should be set to :obj:`True` and a configuration object should be provided\n",
            "     |                    as ``config`` argument. This loading path is slower than converting the PyTorch model in a\n",
            "     |                    TensorFlow model using the provided conversion scripts and loading the TensorFlow model\n",
            "     |                    afterwards.\n",
            "     |                  - :obj:`None` if you are both providing the configuration and state dictionary (resp. with keyword\n",
            "     |                    arguments ``config`` and ``state_dict``).\n",
            "     |          model_args (sequence of positional arguments, `optional`):\n",
            "     |              All remaning positional arguments will be passed to the underlying model's ``__init__`` method.\n",
            "     |          config (:obj:`Union[PretrainedConfig, str]`, `optional`):\n",
            "     |              Can be either:\n",
            "     |      \n",
            "     |                  - an instance of a class derived from :class:`~transformers.PretrainedConfig`,\n",
            "     |                  - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained`.\n",
            "     |      \n",
            "     |              Configuration for the model to use instead of an automatically loaded configuation. Configuration can\n",
            "     |              be automatically loaded when:\n",
            "     |      \n",
            "     |                  - The model is a model provided by the library (loaded with the `shortcut name` string of a\n",
            "     |                    pretrained model).\n",
            "     |                  - The model was saved using :func:`~transformers.TFPreTrainedModel.save_pretrained` and is reloaded\n",
            "     |                    by supplying the save directory.\n",
            "     |                  - The model is loaded by supplying a local directory as ``pretrained_model_name_or_path`` and a\n",
            "     |                    configuration JSON file named `config.json` is found in the directory.\n",
            "     |          from_pt: (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Load the model weights from a PyTorch state_dict save file (see docstring of\n",
            "     |              ``pretrained_model_name_or_path`` argument).\n",
            "     |          cache_dir (:obj:`str`, `optional`):\n",
            "     |              Path to a directory in which a downloaded pretrained model configuration should be cached if the\n",
            "     |              standard cache should not be used.\n",
            "     |          force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to force the (re-)download of the model weights and configuration files, overriding the\n",
            "     |              cached versions if they exist.\n",
            "     |          resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to delete incompletely received files. Will attempt to resume the download if such a\n",
            "     |              file exists.\n",
            "     |          proxies: (:obj:`Dict[str, str], `optional`):\n",
            "     |              A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',\n",
            "     |              'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\n",
            "     |          output_loading_info(:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.\n",
            "     |          local_files_only(:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to only look at local files (e.g., not try doanloading the model).\n",
            "     |          revision(:obj:`str`, `optional`, defaults to :obj:`\"main\"`):\n",
            "     |              The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
            "     |              git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any\n",
            "     |              identifier allowed by git.\n",
            "     |          mirror(:obj:`str`, `optional`, defaults to :obj:`None`):\n",
            "     |              Mirror source to accelerate downloads in China. If you are from China and have an accessibility\n",
            "     |              problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.\n",
            "     |              Please refer to the mirror site for more information.\n",
            "     |          kwargs (remaining dictionary of keyword arguments, `optional`):\n",
            "     |              Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,\n",
            "     |              :obj:`output_attentions=True`). Behaves differently depending on whether a ``config`` is provided or\n",
            "     |              automatically loaded:\n",
            "     |      \n",
            "     |                  - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the\n",
            "     |                    underlying model's ``__init__`` method (we assume all relevant updates to the configuration have\n",
            "     |                    already been done)\n",
            "     |                  - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class\n",
            "     |                    initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of\n",
            "     |                    ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute\n",
            "     |                    with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration\n",
            "     |                    attribute will be passed to the underlying model's ``__init__`` function.\n",
            "     |      \n",
            "     |      Examples::\n",
            "     |      \n",
            "     |          >>> from transformers import BertConfig, TFBertModel\n",
            "     |          >>> # Download model and configuration from S3 and cache.\n",
            "     |          >>> model = TFBertModel.from_pretrained('bert-base-uncased')\n",
            "     |          >>> # Model was saved using `save_pretrained('./test/saved_model/')` (for example purposes, not runnable).\n",
            "     |          >>> model = TFBertModel.from_pretrained('./test/saved_model/')\n",
            "     |          >>> # Update configuration during loading.\n",
            "     |          >>> model = TFBertModel.from_pretrained('bert-base-uncased', output_attentions=True)\n",
            "     |          >>> assert model.config.output_attentions == True\n",
            "     |          >>> # Loading from a Pytorch model file instead of a TensorFlow checkpoint (slower, for example purposes, not runnable).\n",
            "     |          >>> config = BertConfig.from_json_file('./pt_model/my_pt_model_config.json')\n",
            "     |          >>> model = TFBertModel.from_pretrained('./pt_model/my_pytorch_model.bin', from_pt=True, config=config)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            "     |  \n",
            "     |  dummy_inputs\n",
            "     |      Dummy inputs to build the network.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`Dict[str, tf.Tensor]`: The dummy inputs.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            "     |  \n",
            "     |  authorized_missing_keys = None\n",
            "     |  \n",
            "     |  authorized_unexpected_keys = None\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  __setattr__(self, name, value)\n",
            "     |      Support self.foo = trackable syntax.\n",
            "     |  \n",
            "     |  build(self, input_shape)\n",
            "     |      Builds the model based on input shapes received.\n",
            "     |      \n",
            "     |      This is to be used for subclassed models, which do not know at instantiation\n",
            "     |      time what their inputs look like.\n",
            "     |      \n",
            "     |      This method only exists for users who want to call `model.build()` in a\n",
            "     |      standalone way (as a substitute for calling the model on real data to\n",
            "     |      build it). It will never be called by the framework (and thus it will\n",
            "     |      never throw unexpected errors in an unrelated workflow).\n",
            "     |      \n",
            "     |      Args:\n",
            "     |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
            "     |           are tuples, integers, or TensorShapes.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        ValueError:\n",
            "     |          1. In case of invalid user-provided data (not of type tuple,\n",
            "     |             list, or TensorShape).\n",
            "     |          2. If the model requires call arguments that are agnostic\n",
            "     |             to the input shapes (positional or kwarg in call signature).\n",
            "     |          3. If not all layers were properly built.\n",
            "     |          4. If float type inputs are not supported within the layers.\n",
            "     |      \n",
            "     |        In each of these cases, the user should build their model by calling it\n",
            "     |        on real tensor data.\n",
            "     |  \n",
            "     |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, **kwargs)\n",
            "     |      Configures the model for training.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            "     |            `tf.keras.optimizers`.\n",
            "     |          loss: String (name of objective function), objective function or\n",
            "     |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
            "     |            function is any callable with the signature `loss = fn(y_true,\n",
            "     |            y_pred)`, where y_true = ground truth values with shape =\n",
            "     |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
            "     |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
            "     |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
            "     |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
            "     |            used and reduction is set to NONE, return value has the shape\n",
            "     |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
            "     |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
            "     |            use a different loss on each output by passing a dictionary or a list\n",
            "     |            of losses. The loss value that will be minimized by the model will\n",
            "     |            then be the sum of all individual losses.\n",
            "     |          metrics: List of metrics to be evaluated by the model during training\n",
            "     |            and testing. Each of this can be a string (name of a built-in\n",
            "     |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
            "     |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
            "     |            function is any callable with the signature `result = fn(y_true,\n",
            "     |            y_pred)`. To specify different metrics for different outputs of a\n",
            "     |            multi-output model, you could also pass a dictionary, such as\n",
            "     |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
            "     |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
            "     |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
            "     |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            "     |                strings 'accuracy' or 'acc', we convert this to one of\n",
            "     |                `tf.keras.metrics.BinaryAccuracy`,\n",
            "     |                `tf.keras.metrics.CategoricalAccuracy`,\n",
            "     |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
            "     |                function used and the model output shape. We do a similar\n",
            "     |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
            "     |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
            "     |            (Python floats) to weight the loss contributions of different model\n",
            "     |            outputs. The loss value that will be minimized by the model will then\n",
            "     |            be the *weighted sum* of all individual losses, weighted by the\n",
            "     |            `loss_weights` coefficients.\n",
            "     |              If a list, it is expected to have a 1:1 mapping to the model's\n",
            "     |                outputs. If a dict, it is expected to map output names (strings)\n",
            "     |                to scalar coefficients.\n",
            "     |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            "     |            sample_weight or class_weight during training and testing.\n",
            "     |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
            "     |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
            "     |            this as `None` unless your `Model` cannot be run inside a\n",
            "     |            `tf.function`.\n",
            "     |          **kwargs: Any additional arguments. Supported arguments:\n",
            "     |              - `experimental_steps_per_execution`: Int. The number of batches to\n",
            "     |                run during each `tf.function` call. Running multiple batches\n",
            "     |                inside a single `tf.function` call can greatly improve performance\n",
            "     |                on TPUs or small models with a large Python overhead. Note that if\n",
            "     |                this value is set to `N`, `Callback.on_batch` methods will only be\n",
            "     |                called every `N` batches. This currently defaults to `1`. At most,\n",
            "     |                one full epoch will be run each execution. If a number larger than\n",
            "     |                the size of the epoch is passed, the execution will be truncated\n",
            "     |                to the size of the epoch.\n",
            "     |              - `sample_weight_mode` for backward compatibility.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: In case of invalid arguments for\n",
            "     |              `optimizer`, `loss` or `metrics`.\n",
            "     |  \n",
            "     |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
            "     |      Returns the loss value & metrics values for the model in test mode.\n",
            "     |      \n",
            "     |      Computation is done in batches (see the `batch_size` arg.)\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors,\n",
            "     |              if the model has named inputs.\n",
            "     |            - A `tf.data` dataset. Should return a tuple\n",
            "     |              of either `(inputs, targets)` or\n",
            "     |              `(inputs, targets, sample_weights)`.\n",
            "     |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            "     |              or `(inputs, targets, sample_weights)`.\n",
            "     |            A more detailed description of unpacking behavior for iterator types\n",
            "     |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            "     |            for iterator-like inputs` section of `Model.fit`.\n",
            "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "     |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            "     |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            "     |            should not be specified (since targets will be obtained from the\n",
            "     |            iterator/dataset).\n",
            "     |          batch_size: Integer or `None`. Number of samples per batch of\n",
            "     |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
            "     |            specify the `batch_size` if your data is in the form of a dataset,\n",
            "     |            generators, or `keras.utils.Sequence` instances (since they generate\n",
            "     |            batches).\n",
            "     |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            "     |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            "     |            used for weighting the loss function. You can either pass a flat (1D)\n",
            "     |            Numpy array with the same length as the input samples\n",
            "     |              (1:1 mapping between weights and samples), or in the case of\n",
            "     |                temporal data, you can pass a 2D array with shape `(samples,\n",
            "     |                sequence_length)`, to apply a different weight to every timestep\n",
            "     |                of every sample. This argument is not supported when `x` is a\n",
            "     |                dataset, instead pass sample weights as the third element of `x`.\n",
            "     |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            "     |            before declaring the evaluation round finished. Ignored with the\n",
            "     |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            "     |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            "     |            argument is not supported with array inputs.\n",
            "     |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            "     |            callbacks to apply during evaluation. See\n",
            "     |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "     |            input only. Maximum size for the generator queue. If unspecified,\n",
            "     |            `max_queue_size` will default to 10.\n",
            "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "     |            only. Maximum number of processes to spin up when using process-based\n",
            "     |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
            "     |            execute the generator on the main thread.\n",
            "     |          use_multiprocessing: Boolean. Used for generator or\n",
            "     |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "     |            threading. If unspecified, `use_multiprocessing` will default to\n",
            "     |            `False`. Note that because this implementation relies on\n",
            "     |            multiprocessing, you should not pass non-picklable arguments to the\n",
            "     |            generator as they can't be passed easily to children processes.\n",
            "     |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "     |            with each key being the name of the metric. If `False`, they are\n",
            "     |            returned as a list.\n",
            "     |      \n",
            "     |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            "     |      `Model.fit`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Scalar test loss (if the model has a single output and no metrics)\n",
            "     |          or list of scalars (if the model has multiple outputs\n",
            "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            "     |          the display labels for the scalar outputs.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
            "     |          ValueError: in case of invalid arguments.\n",
            "     |  \n",
            "     |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            "     |      Evaluates the model on a data generator. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use Model.evaluate, which supports generators.\n",
            "     |      \n",
            "     |      DEPRECATED:\n",
            "     |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            "     |        to use this endpoint.\n",
            "     |  \n",
            "     |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            "     |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors,\n",
            "     |              if the model has named inputs.\n",
            "     |            - A `tf.data` dataset. Should return a tuple\n",
            "     |              of either `(inputs, targets)` or\n",
            "     |              `(inputs, targets, sample_weights)`.\n",
            "     |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            "     |              or `(inputs, targets, sample_weights)`.\n",
            "     |            A more detailed description of unpacking behavior for iterator types\n",
            "     |            (Dataset, generator, Sequence) is given below.\n",
            "     |          y: Target data. Like the input data `x`,\n",
            "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            "     |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            "     |            or `keras.utils.Sequence` instance, `y` should\n",
            "     |            not be specified (since targets will be obtained from `x`).\n",
            "     |          batch_size: Integer or `None`.\n",
            "     |              Number of samples per gradient update.\n",
            "     |              If unspecified, `batch_size` will default to 32.\n",
            "     |              Do not specify the `batch_size` if your data is in the\n",
            "     |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            "     |              (since they generate batches).\n",
            "     |          epochs: Integer. Number of epochs to train the model.\n",
            "     |              An epoch is an iteration over the entire `x` and `y`\n",
            "     |              data provided.\n",
            "     |              Note that in conjunction with `initial_epoch`,\n",
            "     |              `epochs` is to be understood as \"final epoch\".\n",
            "     |              The model is not trained for a number of iterations\n",
            "     |              given by `epochs`, but merely until the epoch\n",
            "     |              of index `epochs` is reached.\n",
            "     |          verbose: 0, 1, or 2. Verbosity mode.\n",
            "     |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            "     |              Note that the progress bar is not particularly useful when\n",
            "     |              logged to a file, so verbose=2 is recommended when not running\n",
            "     |              interactively (eg, in a production environment).\n",
            "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            "     |              List of callbacks to apply during training.\n",
            "     |              See `tf.keras.callbacks`.\n",
            "     |          validation_split: Float between 0 and 1.\n",
            "     |              Fraction of the training data to be used as validation data.\n",
            "     |              The model will set apart this fraction of the training data,\n",
            "     |              will not train on it, and will evaluate\n",
            "     |              the loss and any model metrics\n",
            "     |              on this data at the end of each epoch.\n",
            "     |              The validation data is selected from the last samples\n",
            "     |              in the `x` and `y` data provided, before shuffling. This argument is\n",
            "     |              not supported when `x` is a dataset, generator or\n",
            "     |             `keras.utils.Sequence` instance.\n",
            "     |          validation_data: Data on which to evaluate\n",
            "     |              the loss and any model metrics at the end of each epoch.\n",
            "     |              The model will not be trained on this data. Thus, note the fact\n",
            "     |              that the validation loss of data provided using `validation_split`\n",
            "     |              or `validation_data` is not affected by regularization layers like\n",
            "     |              noise and dropuout.\n",
            "     |              `validation_data` will override `validation_split`.\n",
            "     |              `validation_data` could be:\n",
            "     |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
            "     |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
            "     |                - dataset\n",
            "     |              For the first two cases, `batch_size` must be provided.\n",
            "     |              For the last case, `validation_steps` could be provided.\n",
            "     |              Note that `validation_data` does not support all the data types that\n",
            "     |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
            "     |          shuffle: Boolean (whether to shuffle the training data\n",
            "     |              before each epoch) or str (for 'batch'). This argument is ignored\n",
            "     |              when `x` is a generator. 'batch' is a special option for dealing\n",
            "     |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            "     |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            "     |          class_weight: Optional dictionary mapping class indices (integers)\n",
            "     |              to a weight (float) value, used for weighting the loss function\n",
            "     |              (during training only).\n",
            "     |              This can be useful to tell the model to\n",
            "     |              \"pay more attention\" to samples from\n",
            "     |              an under-represented class.\n",
            "     |          sample_weight: Optional Numpy array of weights for\n",
            "     |              the training samples, used for weighting the loss function\n",
            "     |              (during training only). You can either pass a flat (1D)\n",
            "     |              Numpy array with the same length as the input samples\n",
            "     |              (1:1 mapping between weights and samples),\n",
            "     |              or in the case of temporal data,\n",
            "     |              you can pass a 2D array with shape\n",
            "     |              `(samples, sequence_length)`,\n",
            "     |              to apply a different weight to every timestep of every sample. This\n",
            "     |              argument is not supported when `x` is a dataset, generator, or\n",
            "     |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
            "     |              as the third element of `x`.\n",
            "     |          initial_epoch: Integer.\n",
            "     |              Epoch at which to start training\n",
            "     |              (useful for resuming a previous training run).\n",
            "     |          steps_per_epoch: Integer or `None`.\n",
            "     |              Total number of steps (batches of samples)\n",
            "     |              before declaring one epoch finished and starting the\n",
            "     |              next epoch. When training with input tensors such as\n",
            "     |              TensorFlow data tensors, the default `None` is equal to\n",
            "     |              the number of samples in your dataset divided by\n",
            "     |              the batch size, or 1 if that cannot be determined. If x is a\n",
            "     |              `tf.data` dataset, and 'steps_per_epoch'\n",
            "     |              is None, the epoch will run until the input dataset is exhausted.\n",
            "     |              When passing an infinitely repeating dataset, you must specify the\n",
            "     |              `steps_per_epoch` argument. This argument is not supported with\n",
            "     |              array inputs.\n",
            "     |          validation_steps: Only relevant if `validation_data` is provided and\n",
            "     |              is a `tf.data` dataset. Total number of steps (batches of\n",
            "     |              samples) to draw before stopping when performing validation\n",
            "     |              at the end of every epoch. If 'validation_steps' is None, validation\n",
            "     |              will run until the `validation_data` dataset is exhausted. In the\n",
            "     |              case of an infinitely repeated dataset, it will run into an\n",
            "     |              infinite loop. If 'validation_steps' is specified and only part of\n",
            "     |              the dataset will be consumed, the evaluation will start from the\n",
            "     |              beginning of the dataset at each epoch. This ensures that the same\n",
            "     |              validation samples are used every time.\n",
            "     |          validation_batch_size: Integer or `None`.\n",
            "     |              Number of samples per validation batch.\n",
            "     |              If unspecified, will default to `batch_size`.\n",
            "     |              Do not specify the `validation_batch_size` if your data is in the\n",
            "     |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            "     |              (since they generate batches).\n",
            "     |          validation_freq: Only relevant if validation data is provided. Integer\n",
            "     |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
            "     |              If an integer, specifies how many training epochs to run before a\n",
            "     |              new validation run is performed, e.g. `validation_freq=2` runs\n",
            "     |              validation every 2 epochs. If a Container, specifies the epochs on\n",
            "     |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
            "     |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
            "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "     |              input only. Maximum size for the generator queue.\n",
            "     |              If unspecified, `max_queue_size` will default to 10.\n",
            "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "     |              only. Maximum number of processes to spin up\n",
            "     |              when using process-based threading. If unspecified, `workers`\n",
            "     |              will default to 1. If 0, will execute the generator on the main\n",
            "     |              thread.\n",
            "     |          use_multiprocessing: Boolean. Used for generator or\n",
            "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
            "     |              `False`. Note that because this implementation relies on\n",
            "     |              multiprocessing, you should not pass non-picklable arguments to\n",
            "     |              the generator as they can't be passed easily to children processes.\n",
            "     |      \n",
            "     |      Unpacking behavior for iterator-like inputs:\n",
            "     |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            "     |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            "     |        yield not only features (x) but optionally targets (y) and sample weights.\n",
            "     |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
            "     |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
            "     |        second and third elements will be used for y and sample_weight\n",
            "     |        respectively. Any other type provided will be wrapped in a length one\n",
            "     |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
            "     |        should still adhere to the top-level tuple structure.\n",
            "     |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            "     |        features, targets, and weights from the keys of a single dict.\n",
            "     |          A notable unsupported data type is the namedtuple. The reason is that\n",
            "     |        it behaves like both an ordered datatype (tuple) and a mapping\n",
            "     |        datatype (dict). So given a namedtuple of the form:\n",
            "     |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            "     |        it is ambiguous whether to reverse the order of the elements when\n",
            "     |        interpreting the value. Even worse is a tuple of the form:\n",
            "     |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            "     |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
            "     |        and sample_weight or passed through as a single element to `x`. As a\n",
            "     |        result the data processing code will simply raise a ValueError if it\n",
            "     |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A `History` object. Its `History.history` attribute is\n",
            "     |          a record of training loss values and metrics values\n",
            "     |          at successive epochs, as well as validation loss values\n",
            "     |          and validation metrics values (if applicable).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: 1. If the model was never compiled or,\n",
            "     |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            "     |      \n",
            "     |          ValueError: In case of mismatch between the provided input data\n",
            "     |              and what the model expects.\n",
            "     |  \n",
            "     |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            "     |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use Model.fit, which supports generators.\n",
            "     |      \n",
            "     |      DEPRECATED:\n",
            "     |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            "     |        this endpoint.\n",
            "     |  \n",
            "     |  get_config(self)\n",
            "     |      Returns the config of the layer.\n",
            "     |      \n",
            "     |      A layer config is a Python dictionary (serializable)\n",
            "     |      containing the configuration of a layer.\n",
            "     |      The same layer can be reinstantiated later\n",
            "     |      (without its trained weights) from this configuration.\n",
            "     |      \n",
            "     |      The config of a layer does not include connectivity\n",
            "     |      information, nor the layer class name. These are handled\n",
            "     |      by `Network` (one layer of abstraction above).\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Python dictionary.\n",
            "     |  \n",
            "     |  get_layer(self, name=None, index=None)\n",
            "     |      Retrieves a layer based on either its name (unique) or index.\n",
            "     |      \n",
            "     |      If `name` and `index` are both provided, `index` will take precedence.\n",
            "     |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          name: String, name of layer.\n",
            "     |          index: Integer, index of layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A layer instance.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: In case of invalid layer name or index.\n",
            "     |  \n",
            "     |  get_weights(self)\n",
            "     |      Retrieves the weights of the model.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A flat list of Numpy arrays.\n",
            "     |  \n",
            "     |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
            "     |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
            "     |      \n",
            "     |      If `by_name` is False weights are loaded based on the network's\n",
            "     |      topology. This means the architecture should be the same as when the weights\n",
            "     |      were saved.  Note that layers that don't have weights are not taken into\n",
            "     |      account in the topological ordering, so adding or removing layers is fine as\n",
            "     |      long as they don't have weights.\n",
            "     |      \n",
            "     |      If `by_name` is True, weights are loaded into layers only if they share the\n",
            "     |      same name. This is useful for fine-tuning or transfer-learning models where\n",
            "     |      some of the layers have changed.\n",
            "     |      \n",
            "     |      Only topological loading (`by_name=False`) is supported when loading weights\n",
            "     |      from the TensorFlow format. Note that topological loading differs slightly\n",
            "     |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
            "     |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
            "     |      TensorFlow format loads based on the object-local names of attributes to\n",
            "     |      which layers are assigned in the `Model`'s constructor.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          filepath: String, path to the weights file to load. For weight files in\n",
            "     |              TensorFlow format, this is the file prefix (the same as was passed\n",
            "     |              to `save_weights`).\n",
            "     |          by_name: Boolean, whether to load weights by name or by topological\n",
            "     |              order. Only topological loading is supported for weight files in\n",
            "     |              TensorFlow format.\n",
            "     |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
            "     |              a mismatch in the number of weights, or a mismatch in the shape of\n",
            "     |              the weight (only valid when `by_name=True`).\n",
            "     |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            "     |              options for loading weights.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          When loading a weight file in TensorFlow format, returns the same status\n",
            "     |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
            "     |          ops are run automatically as soon as the network is built (on first call\n",
            "     |          for user-defined classes inheriting from `Model`, immediately if it is\n",
            "     |          already built).\n",
            "     |      \n",
            "     |          When loading weights in HDF5 format, returns `None`.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ImportError: If h5py is not available and the weight file is in HDF5\n",
            "     |              format.\n",
            "     |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
            "     |            `False`.\n",
            "     |  \n",
            "     |  make_predict_function(self)\n",
            "     |      Creates a function that executes one step of inference.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom inference logic.\n",
            "     |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            "     |      \n",
            "     |      Typically, this method directly controls `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            "     |      logic to `Model.predict_step`.\n",
            "     |      \n",
            "     |      This function is cached the first time `Model.predict` or\n",
            "     |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            "     |      `Model.compile` is called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Function. The function created by this method should accept a\n",
            "     |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            "     |  \n",
            "     |  make_test_function(self)\n",
            "     |      Creates a function that executes one step of evaluation.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom evaluation logic.\n",
            "     |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            "     |      \n",
            "     |      Typically, this method directly controls `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            "     |      logic to `Model.test_step`.\n",
            "     |      \n",
            "     |      This function is cached the first time `Model.evaluate` or\n",
            "     |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            "     |      `Model.compile` is called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Function. The function created by this method should accept a\n",
            "     |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            "     |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            "     |  \n",
            "     |  make_train_function(self)\n",
            "     |      Creates a function that executes one step of training.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom training logic.\n",
            "     |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            "     |      \n",
            "     |      Typically, this method directly controls `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            "     |      logic to `Model.train_step`.\n",
            "     |      \n",
            "     |      This function is cached the first time `Model.fit` or\n",
            "     |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            "     |      `Model.compile` is called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Function. The function created by this method should accept a\n",
            "     |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            "     |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            "     |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            "     |  \n",
            "     |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            "     |      Generates output predictions for the input samples.\n",
            "     |      \n",
            "     |      Computation is done in batches. This method is designed for performance in\n",
            "     |      large scale inputs. For small amount of inputs that fit in one batch,\n",
            "     |      directly using `__call__` is recommended for faster execution, e.g.,\n",
            "     |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            "     |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
            "     |      inference. Also, note the fact that test loss is not affected by\n",
            "     |      regularization layers like noise and dropout.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input samples. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |              (in case the model has multiple inputs).\n",
            "     |            - A `tf.data` dataset.\n",
            "     |            - A generator or `keras.utils.Sequence` instance.\n",
            "     |            A more detailed description of unpacking behavior for iterator types\n",
            "     |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            "     |            for iterator-like inputs` section of `Model.fit`.\n",
            "     |          batch_size: Integer or `None`.\n",
            "     |              Number of samples per batch.\n",
            "     |              If unspecified, `batch_size` will default to 32.\n",
            "     |              Do not specify the `batch_size` if your data is in the\n",
            "     |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            "     |              (since they generate batches).\n",
            "     |          verbose: Verbosity mode, 0 or 1.\n",
            "     |          steps: Total number of steps (batches of samples)\n",
            "     |              before declaring the prediction round finished.\n",
            "     |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            "     |              dataset and `steps` is None, `predict` will\n",
            "     |              run until the input dataset is exhausted.\n",
            "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            "     |              List of callbacks to apply during prediction.\n",
            "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "     |              input only. Maximum size for the generator queue.\n",
            "     |              If unspecified, `max_queue_size` will default to 10.\n",
            "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "     |              only. Maximum number of processes to spin up when using\n",
            "     |              process-based threading. If unspecified, `workers` will default\n",
            "     |              to 1. If 0, will execute the generator on the main thread.\n",
            "     |          use_multiprocessing: Boolean. Used for generator or\n",
            "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
            "     |              `False`. Note that because this implementation relies on\n",
            "     |              multiprocessing, you should not pass non-picklable arguments to\n",
            "     |              the generator as they can't be passed easily to children processes.\n",
            "     |      \n",
            "     |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            "     |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            "     |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            "     |      three methods.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Numpy array(s) of predictions.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
            "     |          ValueError: In case of mismatch between the provided\n",
            "     |              input data and the model's expectations,\n",
            "     |              or in case a stateful model receives a number of samples\n",
            "     |              that is not a multiple of the batch size.\n",
            "     |  \n",
            "     |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            "     |      Generates predictions for the input samples from a data generator. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use Model.predict, which supports generators.\n",
            "     |      \n",
            "     |      DEPRECATED:\n",
            "     |        `Model.predict` now supports generators, so there is no longer any need\n",
            "     |        to use this endpoint.\n",
            "     |  \n",
            "     |  predict_on_batch(self, x)\n",
            "     |      Returns predictions for a single batch of samples.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            "     |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            "     |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Numpy array(s) of predictions.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
            "     |          ValueError: In case of mismatch between given number of inputs and\n",
            "     |            expectations of the model.\n",
            "     |  \n",
            "     |  predict_step(self, data)\n",
            "     |      The logic for one inference step.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom inference logic.\n",
            "     |      This method is called by `Model.make_predict_function`.\n",
            "     |      \n",
            "     |      This method should contain the mathemetical logic for one step of inference.\n",
            "     |      This typically includes the forward pass.\n",
            "     |      \n",
            "     |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings), should be left to\n",
            "     |      `Model.make_predict_function`, which can also be overridden.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        data: A nested structure of `Tensor`s.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        The result of one inference step, typically the output of calling the\n",
            "     |        `Model` on data.\n",
            "     |  \n",
            "     |  reset_metrics(self)\n",
            "     |      Resets the state of all the metrics in the model.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            "     |      \n",
            "     |      >>> x = np.random.random((2, 3))\n",
            "     |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            "     |      >>> _ = model.fit(x, y, verbose=0)\n",
            "     |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            "     |      \n",
            "     |      >>> model.reset_metrics()\n",
            "     |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            "     |  \n",
            "     |  reset_states(self)\n",
            "     |  \n",
            "     |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
            "     |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
            "     |      \n",
            "     |      The savefile includes:\n",
            "     |      \n",
            "     |      - The model architecture, allowing to re-instantiate the model.\n",
            "     |      - The model weights.\n",
            "     |      - The state of the optimizer, allowing to resume training\n",
            "     |          exactly where you left off.\n",
            "     |      \n",
            "     |      This allows you to save the entirety of the state of a model\n",
            "     |      in a single file.\n",
            "     |      \n",
            "     |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
            "     |      The model returned by `load_model` is a compiled model ready to be used\n",
            "     |      (unless the saved model was never compiled in the first place).\n",
            "     |      \n",
            "     |      Models built with the Sequential and Functional API can be saved to both the\n",
            "     |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
            "     |      SavedModel format.\n",
            "     |      \n",
            "     |      Note that the model weights may have different scoped names after being\n",
            "     |      loaded. Scoped names include the model/layer names, such as\n",
            "     |      `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n",
            "     |       access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
            "     |              model.\n",
            "     |          overwrite: Whether to silently overwrite any existing file at the\n",
            "     |              target location, or provide the user with a manual prompt.\n",
            "     |          include_optimizer: If True, save optimizer's state together.\n",
            "     |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
            "     |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
            "     |              and 'h5' in TF 1.X.\n",
            "     |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
            "     |              'tf' format only. Please see the `signatures` argument in\n",
            "     |              `tf.saved_model.save` for details.\n",
            "     |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
            "     |              options for saving to SavedModel.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      from keras.models import load_model\n",
            "     |      \n",
            "     |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
            "     |      del model  # deletes the existing model\n",
            "     |      \n",
            "     |      # returns a compiled model\n",
            "     |      # identical to the previous one\n",
            "     |      model = load_model('my_model.h5')\n",
            "     |      ```\n",
            "     |  \n",
            "     |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            "     |      Saves all layer weights.\n",
            "     |      \n",
            "     |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            "     |      argument.\n",
            "     |      \n",
            "     |      When saving in HDF5 format, the weight file has:\n",
            "     |        - `layer_names` (attribute), a list of strings\n",
            "     |            (ordered names of model layers).\n",
            "     |        - For every layer, a `group` named `layer.name`\n",
            "     |            - For every such layer group, a group attribute `weight_names`,\n",
            "     |                a list of strings\n",
            "     |                (ordered names of weights tensor of the layer).\n",
            "     |            - For every weight in the layer, a dataset\n",
            "     |                storing the weight value, named after the weight tensor.\n",
            "     |      \n",
            "     |      When saving in TensorFlow format, all objects referenced by the network are\n",
            "     |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            "     |      instances or `Optimizer` instances assigned to object attributes. For\n",
            "     |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            "     |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            "     |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            "     |      `Layer` instances must be assigned to object attributes, typically in the\n",
            "     |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            "     |      `tf.keras.Model` for details.\n",
            "     |      \n",
            "     |      While the formats are the same, do not mix `save_weights` and\n",
            "     |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            "     |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            "     |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            "     |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            "     |      `save_weights` for training checkpoints.\n",
            "     |      \n",
            "     |      The TensorFlow format matches objects and variables by starting at a root\n",
            "     |      object, `self` for `save_weights`, and greedily matching attribute\n",
            "     |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            "     |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            "     |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            "     |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            "     |      the `Model`'s variables. See the [guide to training\n",
            "     |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
            "     |      on the TensorFlow format.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          filepath: String or PathLike, path to the file to save the weights to.\n",
            "     |              When saving in TensorFlow format, this is the prefix used for\n",
            "     |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
            "     |              suffix causes weights to be saved in HDF5 format.\n",
            "     |          overwrite: Whether to silently overwrite any existing file at the\n",
            "     |              target location, or provide the user with a manual prompt.\n",
            "     |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            "     |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            "     |              `None` defaults to 'tf'.\n",
            "     |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            "     |              options for saving weights.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ImportError: If h5py is not available when attempting to save in HDF5\n",
            "     |              format.\n",
            "     |          ValueError: For invalid/unknown format arguments.\n",
            "     |  \n",
            "     |  summary(self, line_length=None, positions=None, print_fn=None)\n",
            "     |      Prints a string summary of the network.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          line_length: Total length of printed lines\n",
            "     |              (e.g. set this to adapt the display to different\n",
            "     |              terminal window sizes).\n",
            "     |          positions: Relative or absolute positions of log elements\n",
            "     |              in each line. If not provided,\n",
            "     |              defaults to `[.33, .55, .67, 1.]`.\n",
            "     |          print_fn: Print function to use. Defaults to `print`.\n",
            "     |              It will be called on each line of the summary.\n",
            "     |              You can set it to a custom function\n",
            "     |              in order to capture the string summary.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: if `summary()` is called before the model is built.\n",
            "     |  \n",
            "     |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            "     |      Test the model on a single batch of samples.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            "     |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            "     |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors, if\n",
            "     |            the model has named inputs.\n",
            "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "     |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            "     |          sample_weight: Optional array of the same length as x, containing\n",
            "     |            weights to apply to the model's loss for each sample. In the case of\n",
            "     |            temporal data, you can pass a 2D array with shape (samples,\n",
            "     |            sequence_length), to apply a different weight to every timestep of\n",
            "     |            every sample.\n",
            "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
            "     |            batches.\n",
            "     |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "     |            with each key being the name of the metric. If `False`, they are\n",
            "     |            returned as a list.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Scalar test loss (if the model has a single output and no metrics)\n",
            "     |          or list of scalars (if the model has multiple outputs\n",
            "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            "     |          the display labels for the scalar outputs.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
            "     |          ValueError: In case of invalid user-provided arguments.\n",
            "     |  \n",
            "     |  test_step(self, data)\n",
            "     |      The logic for one evaluation step.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom evaluation logic.\n",
            "     |      This method is called by `Model.make_test_function`.\n",
            "     |      \n",
            "     |      This function should contain the mathemetical logic for one step of\n",
            "     |      evaluation.\n",
            "     |      This typically includes the forward pass, loss calculation, and metrics\n",
            "     |      updates.\n",
            "     |      \n",
            "     |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings), should be left to\n",
            "     |      `Model.make_test_function`, which can also be overridden.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        data: A nested structure of `Tensor`s.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A `dict` containing values that will be passed to\n",
            "     |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            "     |        values of the `Model`'s metrics are returned.\n",
            "     |  \n",
            "     |  to_json(self, **kwargs)\n",
            "     |      Returns a JSON string containing the network configuration.\n",
            "     |      \n",
            "     |      To load a network from a JSON save file, use\n",
            "     |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          **kwargs: Additional keyword arguments\n",
            "     |              to be passed to `json.dumps()`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A JSON string.\n",
            "     |  \n",
            "     |  to_yaml(self, **kwargs)\n",
            "     |      Returns a yaml string containing the network configuration.\n",
            "     |      \n",
            "     |      To load a network from a yaml save file, use\n",
            "     |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            "     |      \n",
            "     |      `custom_objects` should be a dictionary mapping\n",
            "     |      the names of custom losses / layers / etc to the corresponding\n",
            "     |      functions / classes.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          **kwargs: Additional keyword arguments\n",
            "     |              to be passed to `yaml.dump()`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A YAML string.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ImportError: if yaml module is not found.\n",
            "     |  \n",
            "     |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            "     |      Runs a single gradient update on a single batch of data.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          x: Input data. It could be:\n",
            "     |            - A Numpy array (or array-like), or a list of arrays\n",
            "     |                (in case the model has multiple inputs).\n",
            "     |            - A TensorFlow tensor, or a list of tensors\n",
            "     |                (in case the model has multiple inputs).\n",
            "     |            - A dict mapping input names to the corresponding array/tensors,\n",
            "     |                if the model has named inputs.\n",
            "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "     |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            "     |          sample_weight: Optional array of the same length as x, containing\n",
            "     |            weights to apply to the model's loss for each sample. In the case of\n",
            "     |            temporal data, you can pass a 2D array with shape (samples,\n",
            "     |            sequence_length), to apply a different weight to every timestep of\n",
            "     |            every sample.\n",
            "     |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            "     |            weight (float) to apply to the model's loss for the samples from this\n",
            "     |            class during training. This can be useful to tell the model to \"pay\n",
            "     |            more attention\" to samples from an under-represented class.\n",
            "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
            "     |            batches.\n",
            "     |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "     |            with each key being the name of the metric. If `False`, they are\n",
            "     |            returned as a list.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Scalar training loss\n",
            "     |          (if the model has a single output and no metrics)\n",
            "     |          or list of scalars (if the model has multiple outputs\n",
            "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            "     |          the display labels for the scalar outputs.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
            "     |        ValueError: In case of invalid user-provided arguments.\n",
            "     |  \n",
            "     |  train_step(self, data)\n",
            "     |      The logic for one training step.\n",
            "     |      \n",
            "     |      This method can be overridden to support custom training logic.\n",
            "     |      This method is called by `Model.make_train_function`.\n",
            "     |      \n",
            "     |      This method should contain the mathemetical logic for one step of training.\n",
            "     |      This typically includes the forward pass, loss calculation, backpropagation,\n",
            "     |      and metric updates.\n",
            "     |      \n",
            "     |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            "     |      `tf.distribute.Strategy` settings), should be left to\n",
            "     |      `Model.make_train_function`, which can also be overridden.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        data: A nested structure of `Tensor`s.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A `dict` containing values that will be passed to\n",
            "     |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            "     |        values of the `Model`'s metrics are returned. Example:\n",
            "     |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  from_config(config, custom_objects=None) from abc.ABCMeta\n",
            "     |      Creates a layer from its config.\n",
            "     |      \n",
            "     |      This method is the reverse of `get_config`,\n",
            "     |      capable of instantiating the same layer from the config\n",
            "     |      dictionary. It does not handle layer connectivity\n",
            "     |      (handled by Network), nor weights (handled by `set_weights`).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          config: A Python dictionary, typically the\n",
            "     |              output of get_config.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A layer instance.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  __new__(cls, *args, **kwargs)\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
            "     |  \n",
            "     |  distribute_strategy\n",
            "     |      The `tf.distribute.Strategy` this model was created under.\n",
            "     |  \n",
            "     |  layers\n",
            "     |  \n",
            "     |  metrics\n",
            "     |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
            "     |      \n",
            "     |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
            "     |      has been trained/evaluated on actual data.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            "     |      >>> [m.name for m in model.metrics]\n",
            "     |      []\n",
            "     |      \n",
            "     |      >>> x = np.random.random((2, 3))\n",
            "     |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            "     |      >>> model.fit(x, y)\n",
            "     |      >>> [m.name for m in model.metrics]\n",
            "     |      ['loss', 'mae']\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            "     |      >>> output_1 = d(inputs)\n",
            "     |      >>> output_2 = d(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(\n",
            "     |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            "     |      >>> model.add_metric(\n",
            "     |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            "     |      >>> model.fit(x, (y, y))\n",
            "     |      >>> [m.name for m in model.metrics]\n",
            "     |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            "     |      'out_1_acc', 'mean']\n",
            "     |  \n",
            "     |  metrics_names\n",
            "     |      Returns the model's display labels for all outputs.\n",
            "     |      \n",
            "     |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            "     |      trained/evaluated on actual data.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            "     |      >>> model.metrics_names\n",
            "     |      []\n",
            "     |      \n",
            "     |      >>> x = np.random.random((2, 3))\n",
            "     |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            "     |      >>> model.fit(x, y)\n",
            "     |      >>> model.metrics_names\n",
            "     |      ['loss', 'mae']\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            "     |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            "     |      >>> output_1 = d(inputs)\n",
            "     |      >>> output_2 = d(inputs)\n",
            "     |      >>> model = tf.keras.models.Model(\n",
            "     |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            "     |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            "     |      >>> model.fit(x, (y, y))\n",
            "     |      >>> model.metrics_names\n",
            "     |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            "     |      'out_1_acc']\n",
            "     |  \n",
            "     |  non_trainable_weights\n",
            "     |      List of all non-trainable weights tracked by this layer.\n",
            "     |      \n",
            "     |      Non-trainable weights are *not* updated during training. They are expected\n",
            "     |      to be updated manually in `call()`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of non-trainable variables.\n",
            "     |  \n",
            "     |  run_eagerly\n",
            "     |      Settable attribute indicating whether the model should run eagerly.\n",
            "     |      \n",
            "     |      Running eagerly means that your model will be run step by step,\n",
            "     |      like Python code. Your model might run slower, but it should become easier\n",
            "     |      for you to debug it by stepping into individual layer calls.\n",
            "     |      \n",
            "     |      By default, we will attempt to compile your model to a static graph to\n",
            "     |      deliver the best execution performance.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Boolean, whether the model should run eagerly.\n",
            "     |  \n",
            "     |  state_updates\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "     |      \n",
            "     |      Returns the `updates` from all layers that are stateful.\n",
            "     |      \n",
            "     |      This is useful for separating training updates and\n",
            "     |      state updates, e.g. when we need to update a layer's internal state\n",
            "     |      during prediction.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A list of update ops.\n",
            "     |  \n",
            "     |  trainable_weights\n",
            "     |      List of all trainable weights tracked by this layer.\n",
            "     |      \n",
            "     |      Trainable weights are updated via gradient descent during training.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of trainable variables.\n",
            "     |  \n",
            "     |  weights\n",
            "     |      Returns the list of all layer variables/weights.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of variables.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            "     |  \n",
            "     |  __call__(self, *args, **kwargs)\n",
            "     |      Wraps `call`, applying pre- and post-processing steps.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        *args: Positional arguments to be passed to `self.call`.\n",
            "     |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Output tensor(s).\n",
            "     |      \n",
            "     |      Note:\n",
            "     |        - The following optional keyword arguments are reserved for specific uses:\n",
            "     |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            "     |            whether the `call` is meant for training or inference.\n",
            "     |          * `mask`: Boolean input mask.\n",
            "     |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            "     |          layers do), its default value will be set to the mask generated\n",
            "     |          for `inputs` by the previous layer (if `input` did come from\n",
            "     |          a layer that generated a corresponding mask, i.e. if it came from\n",
            "     |          a Keras layer with masking support.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            "     |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            "     |  \n",
            "     |  __delattr__(self, name)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  add_loss(self, losses, **kwargs)\n",
            "     |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            "     |      \n",
            "     |      Some losses (for instance, activity regularization losses) may be dependent\n",
            "     |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            "     |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            "     |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            "     |      of dependencies.\n",
            "     |      \n",
            "     |      This method can be used inside a subclassed layer or model's `call`\n",
            "     |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      class MyLayer(tf.keras.layers.Layer):\n",
            "     |        def call(self, inputs):\n",
            "     |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            "     |          return inputs\n",
            "     |      ```\n",
            "     |      \n",
            "     |      This method can also be called directly on a Functional Model during\n",
            "     |      construction. In this case, any loss Tensors passed to this Model must\n",
            "     |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            "     |      losses become part of the model's topology and are tracked in `get_config`.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      # Activity regularization.\n",
            "     |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            "     |      ```\n",
            "     |      \n",
            "     |      If this is not the case for your loss (if, for example, your loss references\n",
            "     |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            "     |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            "     |      topology since they can't be serialized.\n",
            "     |      \n",
            "     |      Example:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      d = tf.keras.layers.Dense(10)\n",
            "     |      x = d(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      # Weight regularization.\n",
            "     |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            "     |          may also be zero-argument callables which create a loss tensor.\n",
            "     |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            "     |          Accepted values:\n",
            "     |            inputs - Deprecated, will be automatically inferred.\n",
            "     |  \n",
            "     |  add_metric(self, value, name=None, **kwargs)\n",
            "     |      Adds metric tensor to the layer.\n",
            "     |      \n",
            "     |      This method can be used inside the `call()` method of a subclassed layer\n",
            "     |      or model.\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            "     |        def __init__(self):\n",
            "     |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            "     |          self.mean = metrics_module.Mean(name='metric_1')\n",
            "     |      \n",
            "     |        def call(self, inputs):\n",
            "     |          self.add_metric(self.mean(x))\n",
            "     |          self.add_metric(math_ops.reduce_sum(x), name='metric_2')\n",
            "     |          return inputs\n",
            "     |      ```\n",
            "     |      \n",
            "     |      This method can also be called directly on a Functional Model during\n",
            "     |      construction. In this case, any tensor passed to this Model must\n",
            "     |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            "     |      metrics become part of the model's topology and are tracked when you\n",
            "     |      save the model via `save()`.\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            "     |      Functional Model, as shown in the example below, is not supported. This is\n",
            "     |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      inputs = tf.keras.Input(shape=(10,))\n",
            "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      model = tf.keras.Model(inputs, outputs)\n",
            "     |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Args:\n",
            "     |        value: Metric tensor.\n",
            "     |        name: String metric name.\n",
            "     |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            "     |          Accepted values:\n",
            "     |          `aggregation` - When the `value` tensor provided is not the result of\n",
            "     |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            "     |          using a `keras.Metric.Mean`.\n",
            "     |  \n",
            "     |  add_update(self, updates, inputs=None)\n",
            "     |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
            "     |      \n",
            "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      `inputs` is now automatically inferred\n",
            "     |      \n",
            "     |      Weight updates (for instance, the updates of the moving mean and variance\n",
            "     |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            "     |      when calling a layer. Hence, when reusing the same layer on\n",
            "     |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            "     |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            "     |      of dependencies.\n",
            "     |      \n",
            "     |      This call is ignored when eager execution is enabled (in that case, variable\n",
            "     |      updates are run on the fly and thus do not need to be tracked for later\n",
            "     |      execution).\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            "     |          that returns an update op. A zero-arg callable should be passed in\n",
            "     |          order to disable running the updates by setting `trainable=False`\n",
            "     |          on this Layer, when executing in Eager mode.\n",
            "     |        inputs: Deprecated, will be automatically inferred.\n",
            "     |  \n",
            "     |  add_variable(self, *args, **kwargs)\n",
            "     |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.add_weight` method instead.\n",
            "     |  \n",
            "     |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
            "     |      Adds a new variable to the layer.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        name: Variable name.\n",
            "     |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            "     |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
            "     |        initializer: Initializer instance (callable).\n",
            "     |        regularizer: Regularizer instance (callable).\n",
            "     |        trainable: Boolean, whether the variable should be part of the layer's\n",
            "     |          \"trainable_variables\" (e.g. variables, biases)\n",
            "     |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            "     |          Note that `trainable` cannot be `True` if `synchronization`\n",
            "     |          is set to `ON_READ`.\n",
            "     |        constraint: Constraint instance (callable).\n",
            "     |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
            "     |        use_resource: Whether to use `ResourceVariable`.\n",
            "     |        synchronization: Indicates when a distributed a variable will be\n",
            "     |          aggregated. Accepted values are constants defined in the class\n",
            "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            "     |          `AUTO` and the current `DistributionStrategy` chooses\n",
            "     |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            "     |          `trainable` must not be set to `True`.\n",
            "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            "     |          Accepted values are constants defined in the class\n",
            "     |          `tf.VariableAggregation`.\n",
            "     |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            "     |          `collections`, `experimental_autocast` and `caching_device`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
            "     |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
            "     |        instance is returned.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called with partitioned variable regularization and\n",
            "     |          eager execution is enabled.\n",
            "     |        ValueError: When giving unsupported dtype and no initializer or when\n",
            "     |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            "     |  \n",
            "     |  apply(self, inputs, *args, **kwargs)\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.__call__` method instead.\n",
            "     |      \n",
            "     |      This is an alias of `self.__call__`.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        inputs: Input tensor(s).\n",
            "     |        *args: additional positional arguments to be passed to `self.call`.\n",
            "     |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Output tensor(s).\n",
            "     |  \n",
            "     |  compute_mask(self, inputs, mask=None)\n",
            "     |      Computes an output mask tensor.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          inputs: Tensor or list of tensors.\n",
            "     |          mask: Tensor or list of tensors.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          None or a tensor (or list of tensors,\n",
            "     |              one per output tensor of the layer).\n",
            "     |  \n",
            "     |  compute_output_shape(self, input_shape)\n",
            "     |      Computes the output shape of the layer.\n",
            "     |      \n",
            "     |      If the layer has not been built, this method will call `build` on the\n",
            "     |      layer. This assumes that the layer will later be used with inputs that\n",
            "     |      match the input shape provided here.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          input_shape: Shape tuple (tuple of integers)\n",
            "     |              or list of shape tuples (one per output tensor of the layer).\n",
            "     |              Shape tuples can include None for free dimensions,\n",
            "     |              instead of an integer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          An input shape tuple.\n",
            "     |  \n",
            "     |  compute_output_signature(self, input_signature)\n",
            "     |      Compute the output tensor signature of the layer based on the inputs.\n",
            "     |      \n",
            "     |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            "     |      and dtype information for a tensor. This method allows layers to provide\n",
            "     |      output dtype information if it is different from the input dtype.\n",
            "     |      For any layer that doesn't implement this function,\n",
            "     |      the framework will fall back to use `compute_output_shape`, and will\n",
            "     |      assume that the output dtype matches the input dtype.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            "     |          objects, describing a candidate input for the layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            "     |          how the layer would transform the provided input.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            "     |  \n",
            "     |  count_params(self)\n",
            "     |      Count the total number of scalars composing the weights.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          An integer count.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: if the layer isn't yet built\n",
            "     |            (in which case its weights aren't yet defined).\n",
            "     |  \n",
            "     |  get_input_at(self, node_index)\n",
            "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_input_mask_at(self, node_index)\n",
            "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A mask tensor\n",
            "     |          (or list of tensors if the layer has multiple inputs).\n",
            "     |  \n",
            "     |  get_input_shape_at(self, node_index)\n",
            "     |      Retrieves the input shape(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A shape tuple\n",
            "     |          (or list of shape tuples if the layer has multiple inputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_losses_for(self, inputs)\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.losses` instead.\n",
            "     |      \n",
            "     |      Retrieves losses relevant to a specific set of inputs.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        inputs: Input tensor or list/tuple of input tensors.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        List of loss tensors of the layer that depend on `inputs`.\n",
            "     |  \n",
            "     |  get_output_at(self, node_index)\n",
            "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_output_mask_at(self, node_index)\n",
            "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A mask tensor\n",
            "     |          (or list of tensors if the layer has multiple outputs).\n",
            "     |  \n",
            "     |  get_output_shape_at(self, node_index)\n",
            "     |      Retrieves the output shape(s) of a layer at a given node.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          node_index: Integer, index of the node\n",
            "     |              from which to retrieve the attribute.\n",
            "     |              E.g. `node_index=0` will correspond to the\n",
            "     |              first time the layer was called.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          A shape tuple\n",
            "     |          (or list of shape tuples if the layer has multiple outputs).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |  \n",
            "     |  get_updates_for(self, inputs)\n",
            "     |      Deprecated, do NOT use! (deprecated)\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      Please use `layer.updates` instead.\n",
            "     |      \n",
            "     |      Retrieves updates relevant to a specific set of inputs.\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |        inputs: Input tensor or list/tuple of input tensors.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        List of update ops of the layer that depend on `inputs`.\n",
            "     |  \n",
            "     |  set_weights(self, weights)\n",
            "     |      Sets the weights of the layer, from Numpy arrays.\n",
            "     |      \n",
            "     |      The weights of a layer represent the state of the layer. This function\n",
            "     |      sets the weight values from numpy arrays. The weight values should be\n",
            "     |      passed in the order they are created by the layer. Note that the layer's\n",
            "     |      weights must be instantiated before calling this function by calling\n",
            "     |      the layer.\n",
            "     |      \n",
            "     |      For example, a Dense layer returns a list of two values-- per-output\n",
            "     |      weights and the bias value. These can be used to set the weights of another\n",
            "     |      Dense layer:\n",
            "     |      \n",
            "     |      >>> a = tf.keras.layers.Dense(1,\n",
            "     |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            "     |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            "     |      >>> a.get_weights()\n",
            "     |      [array([[1.],\n",
            "     |             [1.],\n",
            "     |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            "     |      >>> b = tf.keras.layers.Dense(1,\n",
            "     |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            "     |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            "     |      >>> b.get_weights()\n",
            "     |      [array([[2.],\n",
            "     |             [2.],\n",
            "     |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            "     |      >>> b.set_weights(a.get_weights())\n",
            "     |      >>> b.get_weights()\n",
            "     |      [array([[1.],\n",
            "     |             [1.],\n",
            "     |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            "     |      \n",
            "     |      Arguments:\n",
            "     |          weights: a list of Numpy arrays. The number\n",
            "     |              of arrays and their shape must match\n",
            "     |              number of the dimensions of the weights\n",
            "     |              of the layer (i.e. it should match the\n",
            "     |              output of `get_weights`).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          ValueError: If the provided weights list does not match the\n",
            "     |              layer's specifications.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            "     |  \n",
            "     |  activity_regularizer\n",
            "     |      Optional regularizer function for the output of this layer.\n",
            "     |  \n",
            "     |  dtype\n",
            "     |      Dtype used by the weights of the layer, set in the constructor.\n",
            "     |  \n",
            "     |  dynamic\n",
            "     |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            "     |  \n",
            "     |  inbound_nodes\n",
            "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            "     |  \n",
            "     |  input\n",
            "     |      Retrieves the input tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one input,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Input tensor or list of input tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        RuntimeError: If called in Eager mode.\n",
            "     |        AttributeError: If no inbound nodes are found.\n",
            "     |  \n",
            "     |  input_mask\n",
            "     |      Retrieves the input mask tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one inbound node,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Input mask tensor (potentially None) or list of input\n",
            "     |          mask tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer is connected to\n",
            "     |          more than one incoming layers.\n",
            "     |  \n",
            "     |  input_shape\n",
            "     |      Retrieves the input shape(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one input,\n",
            "     |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            "     |      have the same shape.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Input shape, as an integer shape tuple\n",
            "     |          (or list of shape tuples, one tuple per input tensor).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer has no defined input_shape.\n",
            "     |          RuntimeError: if called in Eager mode.\n",
            "     |  \n",
            "     |  input_spec\n",
            "     |      `InputSpec` instance(s) describing the input format for this layer.\n",
            "     |      \n",
            "     |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            "     |      the layer to run input compatibility checks when it is called.\n",
            "     |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            "     |      of rank 4. As such, you can set, in `__init__()`:\n",
            "     |      \n",
            "     |      ```python\n",
            "     |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Now, if you try to call the layer on an input that isn't rank 4\n",
            "     |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            "     |      error:\n",
            "     |      \n",
            "     |      ```\n",
            "     |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            "     |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            "     |      ```\n",
            "     |      \n",
            "     |      Input checks that can be specified via `input_spec` include:\n",
            "     |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            "     |      - Shape\n",
            "     |      - Rank (ndim)\n",
            "     |      - Dtype\n",
            "     |      \n",
            "     |      For more information, see `tf.keras.layers.InputSpec`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            "     |  \n",
            "     |  losses\n",
            "     |      List of losses added using the `add_loss()` API.\n",
            "     |      \n",
            "     |      Variable regularization tensors are created when this property is accessed,\n",
            "     |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            "     |      propagate gradients back to the corresponding variables.\n",
            "     |      \n",
            "     |      Examples:\n",
            "     |      \n",
            "     |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            "     |      ...   def call(self, inputs):\n",
            "     |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            "     |      ...     return inputs\n",
            "     |      >>> l = MyLayer()\n",
            "     |      >>> l(np.ones((10, 1)))\n",
            "     |      >>> l.losses\n",
            "     |      [1.0]\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            "     |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            "     |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      >>> model = tf.keras.Model(inputs, outputs)\n",
            "     |      >>> # Activity regularization.\n",
            "     |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            "     |      >>> model.losses\n",
            "     |      [<tf.Tensor 'Abs:0' shape=() dtype=float32>]\n",
            "     |      \n",
            "     |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            "     |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            "     |      >>> x = d(inputs)\n",
            "     |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            "     |      >>> model = tf.keras.Model(inputs, outputs)\n",
            "     |      >>> # Weight regularization.\n",
            "     |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            "     |      >>> model.losses\n",
            "     |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of tensors.\n",
            "     |  \n",
            "     |  name\n",
            "     |      Name of the layer (string), set in the constructor.\n",
            "     |  \n",
            "     |  non_trainable_variables\n",
            "     |  \n",
            "     |  outbound_nodes\n",
            "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            "     |  \n",
            "     |  output\n",
            "     |      Retrieves the output tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one output,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        Output tensor or list of output tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |        AttributeError: if the layer is connected to more than one incoming\n",
            "     |          layers.\n",
            "     |        RuntimeError: if called in Eager mode.\n",
            "     |  \n",
            "     |  output_mask\n",
            "     |      Retrieves the output mask tensor(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has exactly one inbound node,\n",
            "     |      i.e. if it is connected to one incoming layer.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Output mask tensor (potentially None) or list of output\n",
            "     |          mask tensors.\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer is connected to\n",
            "     |          more than one incoming layers.\n",
            "     |  \n",
            "     |  output_shape\n",
            "     |      Retrieves the output shape(s) of a layer.\n",
            "     |      \n",
            "     |      Only applicable if the layer has one output,\n",
            "     |      or if all outputs have the same shape.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          Output shape, as an integer shape tuple\n",
            "     |          (or list of shape tuples, one tuple per output tensor).\n",
            "     |      \n",
            "     |      Raises:\n",
            "     |          AttributeError: if the layer has no defined output shape.\n",
            "     |          RuntimeError: if called in Eager mode.\n",
            "     |  \n",
            "     |  stateful\n",
            "     |  \n",
            "     |  supports_masking\n",
            "     |      Whether this layer supports computing a mask using `compute_mask`.\n",
            "     |  \n",
            "     |  trainable\n",
            "     |  \n",
            "     |  trainable_variables\n",
            "     |      Sequence of trainable variables owned by this module and its submodules.\n",
            "     |      \n",
            "     |      Note: this method uses reflection to find variables on the current instance\n",
            "     |      and submodules. For performance reasons you may wish to cache the result\n",
            "     |      of calling this method if you don't expect the return value to change.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A sequence of variables for the current module (sorted by attribute\n",
            "     |        name) followed by variables from all submodules recursively (breadth\n",
            "     |        first).\n",
            "     |  \n",
            "     |  updates\n",
            "     |      DEPRECATED FUNCTION\n",
            "     |      \n",
            "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            "     |      Instructions for updating:\n",
            "     |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "     |  \n",
            "     |  variables\n",
            "     |      Returns the list of all layer variables/weights.\n",
            "     |      \n",
            "     |      Alias of `self.weights`.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A list of variables.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            "     |  \n",
            "     |  with_name_scope(method) from abc.ABCMeta\n",
            "     |      Decorator to automatically enter the module name scope.\n",
            "     |      \n",
            "     |      >>> class MyModule(tf.Module):\n",
            "     |      ...   @tf.Module.with_name_scope\n",
            "     |      ...   def __call__(self, x):\n",
            "     |      ...     if not hasattr(self, 'w'):\n",
            "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            "     |      ...     return tf.matmul(x, self.w)\n",
            "     |      \n",
            "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            "     |      names included the module name:\n",
            "     |      \n",
            "     |      >>> mod = MyModule()\n",
            "     |      >>> mod(tf.ones([1, 2]))\n",
            "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            "     |      >>> mod.w\n",
            "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            "     |      numpy=..., dtype=float32)>\n",
            "     |      \n",
            "     |      Args:\n",
            "     |        method: The method to wrap.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        The original method wrapped such that it enters the module's name scope.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            "     |  \n",
            "     |  name_scope\n",
            "     |      Returns a `tf.name_scope` instance for this class.\n",
            "     |  \n",
            "     |  submodules\n",
            "     |      Sequence of all sub-modules.\n",
            "     |      \n",
            "     |      Submodules are modules which are properties of this module, or found as\n",
            "     |      properties of modules which are properties of this module (and so on).\n",
            "     |      \n",
            "     |      >>> a = tf.Module()\n",
            "     |      >>> b = tf.Module()\n",
            "     |      >>> c = tf.Module()\n",
            "     |      >>> a.b = b\n",
            "     |      >>> b.c = c\n",
            "     |      >>> list(a.submodules) == [b, c]\n",
            "     |      True\n",
            "     |      >>> list(b.submodules) == [c]\n",
            "     |      True\n",
            "     |      >>> list(c.submodules) == []\n",
            "     |      True\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |        A sequence of all submodules.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from transformers.modeling_tf_utils.TFModelUtilsMixin:\n",
            "     |  \n",
            "     |  num_parameters(self, only_trainable:bool=False) -> int\n",
            "     |      Get the number of (optionally, trainable) parameters in the model.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          only_trainable (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to return only the number of trainable parameters\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :obj:`int`: The number of parameters.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from transformers.generation_tf_utils.TFGenerationMixin:\n",
            "     |  \n",
            "     |  adjust_logits_during_generation(self, logits, **kwargs)\n",
            "     |      Implement in subclasses of :class:`~transformers.PreTrainedModel` for custom behavior to adjust the logits in\n",
            "     |      the generate method.\n",
            "     |  \n",
            "     |  generate(self, input_ids=None, max_length=None, min_length=None, do_sample=None, early_stopping=None, num_beams=None, temperature=None, top_k=None, top_p=None, repetition_penalty=None, bad_words_ids=None, bos_token_id=None, pad_token_id=None, eos_token_id=None, length_penalty=None, no_repeat_ngram_size=None, num_return_sequences=None, attention_mask=None, decoder_start_token_id=None, use_cache=None)\n",
            "     |      Generates sequences for models with a language modeling head. The method currently supports greedy decoding,\n",
            "     |      beam-search decoding, sampling with temperature, sampling with top-k or nucleus sampling.\n",
            "     |      \n",
            "     |      Adapted in part from `Facebook's XLM beam search code\n",
            "     |      <https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529>`__.\n",
            "     |      \n",
            "     |      Apart from :obj:`input_ids` and :obj:`attention_mask`, all the arguments below will default to the value of the\n",
            "     |      attribute of the same name inside the :class:`~transformers.PretrainedConfig` of the model. The default values\n",
            "     |      indicated are the default values of those config.\n",
            "     |      \n",
            "     |      Most of these parameters are explained in more detail in `this blog post\n",
            "     |      <https://huggingface.co/blog/how-to-generate>`__.\n",
            "     |      \n",
            "     |      Parameters:\n",
            "     |      \n",
            "     |          input_ids (:obj:`tf.Tensor` of :obj:`dtype=tf.int32` and shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
            "     |              The sequence used as a prompt for the generation. If :obj:`None` the method initializes it as an empty\n",
            "     |              :obj:`tf.Tensor` of shape :obj:`(1,)`.\n",
            "     |          max_length (:obj:`int`, `optional`, defaults to 20):\n",
            "     |              The maximum length of the sequence to be generated.\n",
            "     |          min_length (:obj:`int`, `optional`, defaults to 10):\n",
            "     |              The minimum length of the sequence to be generated.\n",
            "     |          do_sample (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether or not to use sampling ; use greedy decoding otherwise.\n",
            "     |          early_stopping (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
            "     |              Whether to stop the beam search when at least ``num_beams`` sentences are finished per batch or not.\n",
            "     |          num_beams (:obj:`int`, `optional`, defaults to 1):\n",
            "     |              Number of beams for beam search. 1 means no beam search.\n",
            "     |          temperature (:obj:`float`, `optional`, defaults to 1.0):\n",
            "     |              The value used to module the next token probabilities.\n",
            "     |          top_k (:obj:`int`, `optional`, defaults to 50):\n",
            "     |              The number of highest probability vocabulary tokens to keep for top-k-filtering.\n",
            "     |          top_p (:obj:`float`, `optional`, defaults to 1.0):\n",
            "     |              If set to float < 1, only the most probable tokens with probabilities that add up to ``top_p`` or\n",
            "     |              higher are kept for generation.\n",
            "     |          repetition_penalty (:obj:`float`, `optional`, defaults to 1.0):\n",
            "     |              The parameter for repetition penalty. 1.0 means no penalty. See `this paper\n",
            "     |              <https://arxiv.org/pdf/1909.05858.pdf>`__ for more details.\n",
            "     |          pad_token_id (:obj:`int`, `optional`):\n",
            "     |              The id of the `padding` token.\n",
            "     |          bos_token_id (:obj:`int`, `optional`):\n",
            "     |              The id of the `beginning-of-sequence` token.\n",
            "     |          eos_token_id (:obj:`int`, `optional`):\n",
            "     |              The id of the `end-of-sequence` token.\n",
            "     |          length_penalty (:obj:`float`, `optional`, defaults to 1.0):\n",
            "     |              Exponential penalty to the length. 1.0 means no penalty.\n",
            "     |      \n",
            "     |              Set to values < 1.0 in order to encourage the model to generate shorter sequences, to a value > 1.0 in\n",
            "     |              order to encourage the model to produce longer sequences.\n",
            "     |          no_repeat_ngram_size (:obj:`int`, `optional`, defaults to 0):\n",
            "     |              If set to int > 0, all ngrams of that size can only occur once.\n",
            "     |          bad_words_ids(:obj:`List[int]`, `optional`):\n",
            "     |              List of token ids that are not allowed to be generated. In order to get the tokens of the words that\n",
            "     |              should not appear in the generated text, use :obj:`tokenizer.encode(bad_word, add_prefix_space=True)`.\n",
            "     |          num_return_sequences(:obj:`int`, `optional`, defaults to 1):\n",
            "     |              The number of independently computed returned sequences for each element in the batch.\n",
            "     |          attention_mask (:obj:`tf.Tensor` of :obj:`dtype=tf.int32` and shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
            "     |              Mask to avoid performing attention on padding token indices. Mask values are in ``[0, 1]``, 1 for\n",
            "     |              tokens that are not masked, and 0 for masked tokens.\n",
            "     |      \n",
            "     |              If not provided, will default to a tensor the same shape as :obj:`input_ids` that masks the pad token.\n",
            "     |      \n",
            "     |              `What are attention masks? <../glossary.html#attention-mask>`__\n",
            "     |          decoder_start_token_id (:obj:`int`, `optional`):\n",
            "     |              If an encoder-decoder model starts decoding with a different token than `bos`, the id of that token.\n",
            "     |          use_cache: (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
            "     |              Whether or not the model should use the past last key/values attentions (if applicable to the model) to\n",
            "     |              speed up decoding.\n",
            "     |          model_specific_kwargs:\n",
            "     |              Additional model specific kwargs will be forwarded to the :obj:`forward` function of the model.\n",
            "     |      \n",
            "     |      Return:\n",
            "     |      \n",
            "     |          :obj:`tf.Tensor` of :obj:`dtype=tf.int32` and shape :obj:`(batch_size * num_return_sequences,\n",
            "     |          sequence_length)`: The generated sequences. The second dimension (sequence_length) is either equal to\n",
            "     |          :obj:`max_length` or shorter if all batches finished early due to the :obj:`eos_token_id`.\n",
            "     |      \n",
            "     |      Examples::\n",
            "     |      \n",
            "     |          tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n",
            "     |          model = TFAutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n",
            "     |          outputs = model.generate(max_length=40)  # do greedy decoding\n",
            "     |          print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n",
            "     |      \n",
            "     |          tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n",
            "     |          model = TFAutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n",
            "     |          input_context = 'The dog'\n",
            "     |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            "     |          outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n",
            "     |          for i in range(3): #  3 output sequences were generated\n",
            "     |              print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n",
            "     |      \n",
            "     |          tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n",
            "     |          model = TFAutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n",
            "     |          input_context = 'The dog'\n",
            "     |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            "     |          outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, num_return_sequences=3, do_sample=True)  # generate 3 candidates using sampling\n",
            "     |          for i in range(3): #  3 output sequences were generated\n",
            "     |              print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n",
            "     |      \n",
            "     |          tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n",
            "     |          model = TFAutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n",
            "     |          input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n",
            "     |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            "     |          outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n",
            "     |          print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n",
            "     |      \n",
            "     |          tokenizer = AutoTokenizer.from_pretrained('gpt2')   # Initialize tokenizer\n",
            "     |          model = TFAutoModelWithLMHead.from_pretrained('gpt2')    # Download model and configuration from S3 and cache.\n",
            "     |          input_context = 'My cute dog'\n",
            "     |          bad_words_ids = [tokenizer.encode(bad_word, add_prefix_space=True) for bad_word in ['idiot', 'stupid', 'shut up']]\n",
            "     |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            "     |          outputs = model.generate(input_ids=input_ids, max_length=100, do_sample=True, bad_words_ids=bad_words_ids)  # generate sequences without allowing bad_words to be generated\n",
            "     |  \n",
            "     |  prepare_inputs_for_generation(self, inputs, **kwargs)\n",
            "     |      Implement in subclasses of :class:`~transformers.TFPreTrainedModel` for custom behavior to prepare inputs in\n",
            "     |      the generate method.\n",
            "\n",
            "FUNCTIONS\n",
            "    force_to_return_details(kwargs:dict)\n",
            "        Force a model to output attentions and hidden states due to the fixed\n",
            "        definition of the output batch (the well-defined interface).\n",
            "\n",
            "DATA\n",
            "    logger = <Logger absa.model (WARNING)>\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/aspect_based_sentiment_analysis/models.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441,
          "referenced_widgets": [
            "1cddd104c2d94227a2d44c0f33433707",
            "c56d0df326fb4e5e9711d5b82fa97332",
            "8df5bd8ec08241a2934377cbfbe6e202",
            "95f1aad4c86a4162b9d0920e8a7dd6f3",
            "c16cbbbcd63c415bbde5f4fa527e9b5b",
            "0a7b3b2dd69041fe99ab55752efa2066",
            "107e61cde3f04055b896bfde3073b816",
            "667a6ecd2f1640cb8ce11441d1ade497",
            "87461e08888b4660a54e47f042e152c4",
            "85a08b90c31d40c1962b3722fd083e2a",
            "3ca964f9d6ee40f6a9b34c5869d6970d",
            "c9d8b238b9a54f48b9866eb5513c130d",
            "06a81ae807304a6f9c0b2f41c3528bf2",
            "f5aecdc00472411eb5851eca61c5480b",
            "49ce9337e1ef44349257849668699030",
            "fe126f0a97504c0680bc356bfcb234e9"
          ]
        },
        "id": "JX_nm7bcLMd4",
        "outputId": "d6c393cc-cd90-4fac-a956-a042529d0483"
      },
      "source": [
        "import aspect_based_sentiment_analysis as absa\n",
        "\n",
        "name = 'absa/classifier-rest-0.2'\n",
        "model = absa.BertABSClassifier.from_pretrained(name)\n",
        "tokenizer = absa.AutoTokenizer.from_pretrained(name)\n",
        "professor = absa.Professor(...)     # Explained in detail later on.\n",
        "text_splitter = absa.sentencizer()  # The English CNN model from SpaCy.\n",
        "nlp = absa.Pipeline(model, tokenizer, professor, text_splitter)\n",
        "\n",
        "# Break down the pipeline `call` method.\n",
        "task = nlp.preprocess(text=..., aspects=...)\n",
        "tokenized_examples = nlp.tokenize(task.examples)\n",
        "input_batch = nlp.encode(tokenized_examples)\n",
        "output_batch = nlp.predict(input_batch)\n",
        "predictions = nlp.review(tokenized_examples, output_batch)\n",
        "completed_task = nlp.postprocess(task, predictions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cddd104c2d94227a2d44c0f33433707",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1081.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87461e08888b4660a54e47f042e152c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438206084.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at absa/classifier-rest-0.2 were not used when initializing BertABSClassifier: ['dropout_379']\n",
            "- This IS expected if you are initializing BertABSClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertABSClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of BertABSClassifier were not initialized from the model checkpoint at absa/classifier-rest-0.2 and are newly initialized: ['dropout_37']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a99cdfbaeb47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'absa/classifier-rest-0.2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertABSClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprofessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Explained in detail later on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtext_splitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentencizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# The English CNN model from SpaCy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'aspect_based_sentiment_analysis' has no attribute 'AutoTokenizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTdsF60xn4DW",
        "outputId": "12eb77d5-ab44-4b4a-e3a4-f1ae28bb1f21"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 24.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=829fbef557b448b8c2accdbc776ed3986c8eb7ba47809bc8fcab66f1264f28b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "2893a1681346476a810e95dcccc1cf06",
            "45afb21d59a648a99c12f5534c0a02e0",
            "f32901a56e0847eb87d26ee260b19255",
            "ddd77cb7e1b94698b7957811360bf15c",
            "78320b3fcc774f0596d061229fd357d1",
            "e0889afbce714b8d82081ad8090ee751",
            "c6e786d037374a4286bd4817ca953527",
            "f40645d54c3146249c4feee859ec5547",
            "90782ae19524410e9dd05e3a69bcc317",
            "55a282c0f05d4933a37cd30a11e66623",
            "efb139b0439244989931a11950ce40c4",
            "f4462d9224384dc1ada6c56d5ef74457",
            "13912e46a73048d1acc6d14ed0bfb197",
            "84de798a767248db9fb4f54199071541",
            "4f35516fd86d4fc9a2a7119f68234787",
            "636484925ff74c1787d8253bba87e9fa",
            "2d93bc91733b402c961873a8a81933fc",
            "38f73f92f4dc4201bc61c7fa483ae33a",
            "436ea7b4cd3e4b34a8e2be38707d46d0",
            "fb2ef37a6d7146fda1657b258c7c3ae6",
            "4aa9bc1a16aa441ca68a9ed9c2d6f572",
            "a960736bbd4347fb9258fc7653731357",
            "007b71b5ad4f4f7790f90dc2992a04ad",
            "46eb97faa08948498cdc54544096ddba",
            "47a17ed6402e4638a7960608753ed249",
            "286b5f5c1e104a189a1e222186805169",
            "fd6e93142657495cb8c8fe56641a300b",
            "78bb4789ba7348d19f00eef442427984",
            "61d422d218794e568c2c5cf7f7f3d967",
            "00a4351a34ec402b98e070df07afd112",
            "c3627427f043476289b4f6d072a19ba5",
            "ef7802cca85b4199b7c8dc0c2f46eee0",
            "d327dd3d6a574069b749668295206237",
            "fe69513485e24ede9d72b5936300167d",
            "76d3453f474e42649a42c05bdaa5af14",
            "b63dec87328e489ea367f08cbf11ded8",
            "28d96e05da9448ac995e0ab6b1a914fa",
            "73f250d5afe1479c808c6f0651afdd7c",
            "c27a6dd3109d4a5ca85d5f690d864690",
            "7818d8436f744fa199fe2ff514be65a9",
            "e1cdacce24e04fa8a66c02d9bbde0827",
            "e807b91bdf854a6a8efd2ae3e62023d3",
            "cb172b0fc5c8486991154c27170afa37",
            "a726251ccc794684ad24b512d69068a5",
            "0729f35707614a05bc1be7bd844446b3",
            "bc830575dbef413192420fcecee66948",
            "09d0c3d81a0c40338f24cd96c6bd004a",
            "0508e589026740ed8b5e2039ea7fa4af"
          ]
        },
        "id": "FmKJ4d__LMkT",
        "outputId": "863a8137-9982-4235-c775-b3c60359106a"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"Professors need to undergo a presentation and Instruction Design skills. They were talking a lot and everything was going over my head, the reason was there were not visual prompt for the examples, specifically in the last week.\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2893a1681346476a810e95dcccc1cf06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=829.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90782ae19524410e9dd05e3a69bcc317",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d93bc91733b402c961873a8a81933fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47a17ed6402e4638a7960608753ed249",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d327dd3d6a574069b749668295206237",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=59.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1cdacce24e04fa8a66c02d9bbde0827",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433316646.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[{'word': 'Design', 'score': 0.8305954337120056, 'entity': 'I-MISC', 'index': 11}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WeMqU5tLMnZ",
        "outputId": "82ef7e3e-1b37-45bf-a946-14e313abe16a"
      },
      "source": [
        "example = \"Professor need to undergo a presentation and Instruction Design skills. They were talking a lot and everything was going over my head, the reason was there were not visual prompt for the examples, specifically in the last week.\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'word': 'Design', 'score': 0.6930969953536987, 'entity': 'I-MISC', 'index': 10}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htti5XldLMqU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPF5V7vRLMtk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0NhabSQLMwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP8pkIb3LMzw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM0abqrLLM25"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v2Td2GMLM6b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}